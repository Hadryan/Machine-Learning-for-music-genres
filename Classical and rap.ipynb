{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>artists</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>popularity</th>\n",
       "      <th>key</th>\n",
       "      <th>mode</th>\n",
       "      <th>count</th>\n",
       "      <th>genres</th>\n",
       "      <th>primary_genres</th>\n",
       "      <th>secondary_genres</th>\n",
       "      <th>PrimarynSecondary_genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26854</td>\n",
       "      <td>Young Boss</td>\n",
       "      <td>0.145000</td>\n",
       "      <td>0.986000</td>\n",
       "      <td>229669.0000</td>\n",
       "      <td>0.597000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.197000</td>\n",
       "      <td>-6.809000</td>\n",
       "      <td>0.308000</td>\n",
       "      <td>115.004000</td>\n",
       "      <td>0.761000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>['vapor trap']</td>\n",
       "      <td>rap</td>\n",
       "      <td>trap</td>\n",
       "      <td>rap/trap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>113</td>\n",
       "      <td>4B</td>\n",
       "      <td>0.004410</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>224052.0000</td>\n",
       "      <td>0.851000</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>0.093900</td>\n",
       "      <td>-4.610000</td>\n",
       "      <td>0.319000</td>\n",
       "      <td>150.054000</td>\n",
       "      <td>0.573000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>['brostep', 'electro house', 'electronic trap']</td>\n",
       "      <td>rap</td>\n",
       "      <td>trap</td>\n",
       "      <td>rap/trap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12857</td>\n",
       "      <td>Keith Ape</td>\n",
       "      <td>0.030928</td>\n",
       "      <td>0.734000</td>\n",
       "      <td>236647.0000</td>\n",
       "      <td>0.701000</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.202000</td>\n",
       "      <td>-5.305500</td>\n",
       "      <td>0.166100</td>\n",
       "      <td>129.040000</td>\n",
       "      <td>0.339500</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>['korean trap', 'underground hip hop']</td>\n",
       "      <td>rap</td>\n",
       "      <td>trap</td>\n",
       "      <td>rap/trap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18347</td>\n",
       "      <td>Paloma Mami</td>\n",
       "      <td>0.411000</td>\n",
       "      <td>0.876000</td>\n",
       "      <td>159132.0000</td>\n",
       "      <td>0.568000</td>\n",
       "      <td>0.002740</td>\n",
       "      <td>0.187000</td>\n",
       "      <td>-5.755000</td>\n",
       "      <td>0.053300</td>\n",
       "      <td>98.027000</td>\n",
       "      <td>0.593000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>['latin pop', 'reggaeton chileno', 'trap chile...</td>\n",
       "      <td>rap</td>\n",
       "      <td>trap</td>\n",
       "      <td>rap/trap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20074</td>\n",
       "      <td>Rich The Kid</td>\n",
       "      <td>0.104304</td>\n",
       "      <td>0.810042</td>\n",
       "      <td>194635.9167</td>\n",
       "      <td>0.640417</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>0.192833</td>\n",
       "      <td>-6.649042</td>\n",
       "      <td>0.225142</td>\n",
       "      <td>132.294208</td>\n",
       "      <td>0.504083</td>\n",
       "      <td>68.208333</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>['atl hip hop', 'hip hop', 'melodic rap', 'pop...</td>\n",
       "      <td>rap</td>\n",
       "      <td>trap</td>\n",
       "      <td>rap/trap</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id       artists  acousticness  danceability  duration_ms    energy  \\\n",
       "0  26854    Young Boss      0.145000      0.986000  229669.0000  0.597000   \n",
       "1    113            4B      0.004410      0.630000  224052.0000  0.851000   \n",
       "2  12857     Keith Ape      0.030928      0.734000  236647.0000  0.701000   \n",
       "3  18347   Paloma Mami      0.411000      0.876000  159132.0000  0.568000   \n",
       "4  20074  Rich The Kid      0.104304      0.810042  194635.9167  0.640417   \n",
       "\n",
       "   instrumentalness  liveness  loudness  speechiness       tempo   valence  \\\n",
       "0          0.000002  0.197000 -6.809000     0.308000  115.004000  0.761000   \n",
       "1          0.021800  0.093900 -4.610000     0.319000  150.054000  0.573000   \n",
       "2          0.000004  0.202000 -5.305500     0.166100  129.040000  0.339500   \n",
       "3          0.002740  0.187000 -5.755000     0.053300   98.027000  0.593000   \n",
       "4          0.000338  0.192833 -6.649042     0.225142  132.294208  0.504083   \n",
       "\n",
       "   popularity  key  mode  count  \\\n",
       "0   44.000000    8     1      1   \n",
       "1   54.000000    1     1      1   \n",
       "2   61.000000    9     1      2   \n",
       "3   74.000000    0     1      2   \n",
       "4   68.208333   11     1     24   \n",
       "\n",
       "                                              genres primary_genres  \\\n",
       "0                                     ['vapor trap']            rap   \n",
       "1    ['brostep', 'electro house', 'electronic trap']            rap   \n",
       "2             ['korean trap', 'underground hip hop']            rap   \n",
       "3  ['latin pop', 'reggaeton chileno', 'trap chile...            rap   \n",
       "4  ['atl hip hop', 'hip hop', 'melodic rap', 'pop...            rap   \n",
       "\n",
       "  secondary_genres PrimarynSecondary_genres  \n",
       "0             trap                 rap/trap  \n",
       "1             trap                 rap/trap  \n",
       "2             trap                 rap/trap  \n",
       "3             trap                 rap/trap  \n",
       "4             trap                 rap/trap  "
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(os.path.join('Data', 'w_secondaryGenre.csv'))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>key</th>\n",
       "      <th>mode</th>\n",
       "      <th>secondary_genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.145000</td>\n",
       "      <td>0.986000</td>\n",
       "      <td>229669.0000</td>\n",
       "      <td>0.597000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.197000</td>\n",
       "      <td>-6.809000</td>\n",
       "      <td>0.308000</td>\n",
       "      <td>115.004000</td>\n",
       "      <td>0.761000</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>trap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004410</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>224052.0000</td>\n",
       "      <td>0.851000</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>0.093900</td>\n",
       "      <td>-4.610000</td>\n",
       "      <td>0.319000</td>\n",
       "      <td>150.054000</td>\n",
       "      <td>0.573000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>trap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.030928</td>\n",
       "      <td>0.734000</td>\n",
       "      <td>236647.0000</td>\n",
       "      <td>0.701000</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.202000</td>\n",
       "      <td>-5.305500</td>\n",
       "      <td>0.166100</td>\n",
       "      <td>129.040000</td>\n",
       "      <td>0.339500</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>trap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.411000</td>\n",
       "      <td>0.876000</td>\n",
       "      <td>159132.0000</td>\n",
       "      <td>0.568000</td>\n",
       "      <td>0.002740</td>\n",
       "      <td>0.187000</td>\n",
       "      <td>-5.755000</td>\n",
       "      <td>0.053300</td>\n",
       "      <td>98.027000</td>\n",
       "      <td>0.593000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>trap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.104304</td>\n",
       "      <td>0.810042</td>\n",
       "      <td>194635.9167</td>\n",
       "      <td>0.640417</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>0.192833</td>\n",
       "      <td>-6.649042</td>\n",
       "      <td>0.225142</td>\n",
       "      <td>132.294208</td>\n",
       "      <td>0.504083</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>trap</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acousticness  danceability  duration_ms    energy  instrumentalness  \\\n",
       "0      0.145000      0.986000  229669.0000  0.597000          0.000002   \n",
       "1      0.004410      0.630000  224052.0000  0.851000          0.021800   \n",
       "2      0.030928      0.734000  236647.0000  0.701000          0.000004   \n",
       "3      0.411000      0.876000  159132.0000  0.568000          0.002740   \n",
       "4      0.104304      0.810042  194635.9167  0.640417          0.000338   \n",
       "\n",
       "   liveness  loudness  speechiness       tempo   valence  key  mode  \\\n",
       "0  0.197000 -6.809000     0.308000  115.004000  0.761000    8     1   \n",
       "1  0.093900 -4.610000     0.319000  150.054000  0.573000    1     1   \n",
       "2  0.202000 -5.305500     0.166100  129.040000  0.339500    9     1   \n",
       "3  0.187000 -5.755000     0.053300   98.027000  0.593000    0     1   \n",
       "4  0.192833 -6.649042     0.225142  132.294208  0.504083   11     1   \n",
       "\n",
       "  secondary_genres  \n",
       "0             trap  \n",
       "1             trap  \n",
       "2             trap  \n",
       "3             trap  \n",
       "4             trap  "
      ]
     },
     "execution_count": 590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data=data.drop([\"id\",\"artists\",\"count\",\"genres\",\"popularity\",\"primary_genres\",\"PrimarynSecondary_genres\"],axis=1)\n",
    "cleaned_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 12) (700,)\n"
     ]
    }
   ],
   "source": [
    "X = cleaned_data.drop(\"secondary_genres\", axis=1)\n",
    "y = cleaned_data[\"secondary_genres\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale your data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_Scaler=MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_Scaler.transform(X_train)\n",
    "X_test_scaled = X_Scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.7904761904761904\n",
      "Testing Data Score: 0.7657142857142857\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {classifier.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 Predictions:   ['cool jazz' 'cool jazz' 'texas country' 'cool jazz' 'trap'\n",
      " 'electro house' 'electro house' 'salsa' 'texas country' 'trap']\n",
      "First 10 Actual labels: ['cool jazz', 'cool jazz', 'texas country', 'cool jazz', 'texas country', 'alternative metal', 'electro house', 'salsa', 'texas country', 'electro house']\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test_scaled)\n",
    "print(f\"First 10 Predictions:   {predictions[:10]}\")\n",
    "print(f\"First 10 Actual labels: {y_test[:10].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cool jazz</td>\n",
       "      <td>cool jazz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cool jazz</td>\n",
       "      <td>cool jazz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>texas country</td>\n",
       "      <td>texas country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cool jazz</td>\n",
       "      <td>cool jazz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trap</td>\n",
       "      <td>texas country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>texas country</td>\n",
       "      <td>texas country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>performance</td>\n",
       "      <td>performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>texas country</td>\n",
       "      <td>electro house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>cool jazz</td>\n",
       "      <td>cool jazz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>trap</td>\n",
       "      <td>trap</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Prediction         Actual\n",
       "0        cool jazz      cool jazz\n",
       "1        cool jazz      cool jazz\n",
       "2    texas country  texas country\n",
       "3        cool jazz      cool jazz\n",
       "4             trap  texas country\n",
       "..             ...            ...\n",
       "170  texas country  texas country\n",
       "171    performance    performance\n",
       "172  texas country  electro house\n",
       "173      cool jazz      cool jazz\n",
       "174           trap           trap\n",
       "\n",
       "[175 rows x 2 columns]"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"Prediction\": predictions, \"Actual\": y_test}).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "plot_confusion_matrix(classifier, X_test_scaled, y_test, cmap=plt.cm.Blues)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'penalty': ['l1','l2'],\n",
    "              'C': [0.0001, 0.0005, 0.001, 0.005]}\n",
    "grid = GridSearchCV(classifier, param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] C=0.0001, penalty=l1 ............................................\n",
      "[CV] .................. C=0.0001, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=0.0001, penalty=l1 ............................................\n",
      "[CV] .................. C=0.0001, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=0.0001, penalty=l1 ............................................\n",
      "[CV] .................. C=0.0001, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=0.0001, penalty=l1 ............................................\n",
      "[CV] .................. C=0.0001, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=0.0001, penalty=l1 ............................................\n",
      "[CV] .................. C=0.0001, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=0.0001, penalty=l2 ............................................\n",
      "[CV] ................ C=0.0001, penalty=l2, score=0.162, total=   0.0s\n",
      "[CV] C=0.0001, penalty=l2 ............................................\n",
      "[CV] ................ C=0.0001, penalty=l2, score=0.162, total=   0.0s\n",
      "[CV] C=0.0001, penalty=l2 ............................................\n",
      "[CV] ................ C=0.0001, penalty=l2, score=0.162, total=   0.0s\n",
      "[CV] C=0.0001, penalty=l2 ............................................\n",
      "[CV] ................ C=0.0001, penalty=l2, score=0.162, total=   0.0s\n",
      "[CV] C=0.0001, penalty=l2 ............................................\n",
      "[CV] ................ C=0.0001, penalty=l2, score=0.152, total=   0.0s\n",
      "[CV] C=0.0005, penalty=l1 ............................................\n",
      "[CV] .................. C=0.0005, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=0.0005, penalty=l1 ............................................\n",
      "[CV] .................. C=0.0005, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=0.0005, penalty=l1 ............................................\n",
      "[CV] .................. C=0.0005, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=0.0005, penalty=l1 ............................................\n",
      "[CV] .................. C=0.0005, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=0.0005, penalty=l1 ............................................\n",
      "[CV] .................. C=0.0005, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=0.0005, penalty=l2 ............................................\n",
      "[CV] ................ C=0.0005, penalty=l2, score=0.162, total=   0.0s\n",
      "[CV] C=0.0005, penalty=l2 ............................................\n",
      "[CV] ................ C=0.0005, penalty=l2, score=0.162, total=   0.0s\n",
      "[CV] C=0.0005, penalty=l2 ............................................\n",
      "[CV] ................ C=0.0005, penalty=l2, score=0.162, total=   0.0s\n",
      "[CV] C=0.0005, penalty=l2 ............................................\n",
      "[CV] ................ C=0.0005, penalty=l2, score=0.162, total=   0.0s\n",
      "[CV] C=0.0005, penalty=l2 ............................................\n",
      "[CV] ................ C=0.0005, penalty=l2, score=0.152, total=   0.0s\n",
      "[CV] C=0.001, penalty=l1 .............................................\n",
      "[CV] ................... C=0.001, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=0.001, penalty=l1 .............................................\n",
      "[CV] ................... C=0.001, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=0.001, penalty=l1 .............................................\n",
      "[CV] ................... C=0.001, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=0.001, penalty=l1 .............................................\n",
      "[CV] ................... C=0.001, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=0.001, penalty=l1 .............................................\n",
      "[CV] ................... C=0.001, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=0.001, penalty=l2 .............................................\n",
      "[CV] ................. C=0.001, penalty=l2, score=0.171, total=   0.0s\n",
      "[CV] C=0.001, penalty=l2 .............................................\n",
      "[CV] ................. C=0.001, penalty=l2, score=0.162, total=   0.0s\n",
      "[CV] C=0.001, penalty=l2 .............................................\n",
      "[CV] ................. C=0.001, penalty=l2, score=0.162, total=   0.0s\n",
      "[CV] C=0.001, penalty=l2 .............................................\n",
      "[CV] ................. C=0.001, penalty=l2, score=0.162, total=   0.0s\n",
      "[CV] C=0.001, penalty=l2 .............................................\n",
      "[CV] ................. C=0.001, penalty=l2, score=0.152, total=   0.0s\n",
      "[CV] C=0.005, penalty=l1 .............................................\n",
      "[CV] ................... C=0.005, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=0.005, penalty=l1 .............................................\n",
      "[CV] ................... C=0.005, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=0.005, penalty=l1 .............................................\n",
      "[CV] ................... C=0.005, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=0.005, penalty=l1 .............................................\n",
      "[CV] ................... C=0.005, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=0.005, penalty=l1 .............................................\n",
      "[CV] ................... C=0.005, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=0.005, penalty=l2 .............................................\n",
      "[CV] ................. C=0.005, penalty=l2, score=0.295, total=   0.0s\n",
      "[CV] C=0.005, penalty=l2 .............................................\n",
      "[CV] ................. C=0.005, penalty=l2, score=0.333, total=   0.0s\n",
      "[CV] C=0.005, penalty=l2 .............................................\n",
      "[CV] ................. C=0.005, penalty=l2, score=0.371, total=   0.0s\n",
      "[CV] C=0.005, penalty=l2 .............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "D:\\Anaconda\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\Anaconda\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "D:\\Anaconda\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\Anaconda\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Anaconda\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\Anaconda\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Anaconda\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\Anaconda\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=0.005, penalty=l2, score=0.352, total=   0.0s\n",
      "[CV] C=0.005, penalty=l2 .............................................\n",
      "[CV] ................. C=0.005, penalty=l2, score=0.305, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(),\n",
       "             param_grid={'C': [0.0001, 0.0005, 0.001, 0.005],\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.005, 'penalty': 'l2'}\n",
      "0.33142857142857146\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7314285714285714"
      ]
     },
     "execution_count": 600,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train_scaled, y_train)\n",
    "clf.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8228571428571428"
      ]
     },
     "execution_count": 601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "rf = rf.fit(X_train_scaled, y_train)\n",
    "rf.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = cleaned_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.15466722681804446, 'acousticness'),\n",
       " (0.1514583942046011, 'danceability'),\n",
       " (0.14385062961490405, 'energy'),\n",
       " (0.1209784664447276, 'valence'),\n",
       " (0.10494505915158352, 'loudness'),\n",
       " (0.10248468336882507, 'speechiness'),\n",
       " (0.06584079790415677, 'instrumentalness'),\n",
       " (0.04798841202976639, 'tempo'),\n",
       " (0.04738223000478686, 'duration_ms'),\n",
       " (0.028972311249221692, 'liveness'),\n",
       " (0.020428497873880857, 'key'),\n",
       " (0.011003291335501375, 'mode')]"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(rf.feature_importances_, feature_names), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 400, num = 2)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 20, num = 2)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators': n_estimators,\n",
    "               \n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               }\n",
    "grid = GridSearchCV(rf, param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV] max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200, score=0.733, total=   0.4s\n",
      "[CV] max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200, score=0.838, total=   0.3s\n",
      "[CV] max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200, score=0.810, total=   0.3s\n",
      "[CV] max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200, score=0.857, total=   0.3s\n",
      "[CV] max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200, score=0.838, total=   0.3s\n",
      "[CV] max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=400, score=0.733, total=   0.6s\n",
      "[CV] max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=400, score=0.857, total=   0.6s\n",
      "[CV] max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=400, score=0.771, total=   0.6s\n",
      "[CV] max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=400, score=0.876, total=   0.6s\n",
      "[CV] max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=400, score=0.857, total=   0.6s\n",
      "[CV] max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200, score=0.743, total=   0.3s\n",
      "[CV] max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200, score=0.829, total=   0.3s\n",
      "[CV] max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200, score=0.781, total=   0.3s\n",
      "[CV] max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200, score=0.867, total=   0.3s\n",
      "[CV] max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200, score=0.848, total=   0.3s\n",
      "[CV] max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=400, score=0.733, total=   0.6s\n",
      "[CV] max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=400, score=0.857, total=   0.6s\n",
      "[CV] max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=400, score=0.781, total=   0.6s\n",
      "[CV] max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=400, score=0.867, total=   0.6s\n",
      "[CV] max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=400, score=0.848, total=   0.6s\n",
      "[CV] max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200, score=0.733, total=   0.3s\n",
      "[CV] max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200, score=0.848, total=   0.3s\n",
      "[CV] max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200, score=0.781, total=   0.3s\n",
      "[CV] max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200, score=0.867, total=   0.3s\n",
      "[CV] max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200, score=0.857, total=   0.3s\n",
      "[CV] max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=400, score=0.743, total=   0.6s\n",
      "[CV] max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=400, score=0.857, total=   0.6s\n",
      "[CV] max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=400, score=0.771, total=   0.6s\n",
      "[CV] max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=400, score=0.886, total=   0.6s\n",
      "[CV] max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=400, score=0.848, total=   0.6s\n",
      "[CV] max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200, score=0.752, total=   0.3s\n",
      "[CV] max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200, score=0.857, total=   0.3s\n",
      "[CV] max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200, score=0.771, total=   0.3s\n",
      "[CV] max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200, score=0.857, total=   0.3s\n",
      "[CV] max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200, score=0.848, total=   0.3s\n",
      "[CV] max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=400, score=0.733, total=   0.6s\n",
      "[CV] max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=400, score=0.857, total=   0.6s\n",
      "[CV] max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=400, score=0.790, total=   0.6s\n",
      "[CV] max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=400, score=0.876, total=   0.6s\n",
      "[CV] max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=400, score=0.848, total=   0.6s\n",
      "[CV] max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200, score=0.743, total=   0.3s\n",
      "[CV] max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200, score=0.876, total=   0.3s\n",
      "[CV] max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200, score=0.790, total=   0.3s\n",
      "[CV] max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200, score=0.895, total=   0.3s\n",
      "[CV] max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200, score=0.848, total=   0.3s\n",
      "[CV] max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=400, score=0.733, total=   0.6s\n",
      "[CV] max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=400, score=0.867, total=   0.6s\n",
      "[CV] max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=400 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=400, score=0.790, total=   0.6s\n",
      "[CV] max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=400, score=0.848, total=   0.6s\n",
      "[CV] max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=400, score=0.857, total=   0.6s\n",
      "[CV] max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200, score=0.733, total=   0.3s\n",
      "[CV] max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200, score=0.857, total=   0.3s\n",
      "[CV] max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200, score=0.790, total=   0.3s\n",
      "[CV] max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200, score=0.857, total=   0.3s\n",
      "[CV] max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200, score=0.848, total=   0.3s\n",
      "[CV] max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=400, score=0.733, total=   0.6s\n",
      "[CV] max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=400, score=0.857, total=   0.6s\n",
      "[CV] max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=400, score=0.790, total=   0.6s\n",
      "[CV] max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=400, score=0.857, total=   0.6s\n",
      "[CV] max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=400, score=0.838, total=   0.6s\n",
      "[CV] max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200, score=0.752, total=   0.3s\n",
      "[CV] max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200, score=0.838, total=   0.3s\n",
      "[CV] max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200, score=0.810, total=   0.3s\n",
      "[CV] max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200, score=0.857, total=   0.3s\n",
      "[CV] max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200, score=0.838, total=   0.3s\n",
      "[CV] max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=400, score=0.743, total=   0.6s\n",
      "[CV] max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=400, score=0.857, total=   0.6s\n",
      "[CV] max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=400, score=0.771, total=   0.6s\n",
      "[CV] max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=400, score=0.867, total=   0.7s\n",
      "[CV] max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=400, score=0.848, total=   0.6s\n",
      "[CV] max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200, score=0.762, total=   0.3s\n",
      "[CV] max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200, score=0.857, total=   0.3s\n",
      "[CV] max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200, score=0.781, total=   0.3s\n",
      "[CV] max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200, score=0.876, total=   0.3s\n",
      "[CV] max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200, score=0.829, total=   0.3s\n",
      "[CV] max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=400, score=0.733, total=   0.6s\n",
      "[CV] max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=400, score=0.838, total=   0.6s\n",
      "[CV] max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=400, score=0.781, total=   0.6s\n",
      "[CV] max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=400, score=0.867, total=   0.6s\n",
      "[CV] max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=400, score=0.838, total=   0.6s\n",
      "[CV] max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200, score=0.733, total=   0.3s\n",
      "[CV] max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200, score=0.867, total=   0.3s\n",
      "[CV] max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200, score=0.790, total=   0.3s\n",
      "[CV] max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200, score=0.876, total=   0.3s\n",
      "[CV] max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200, score=0.848, total=   0.3s\n",
      "[CV] max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=400, score=0.733, total=   0.6s\n",
      "[CV] max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=400, score=0.867, total=   0.6s\n",
      "[CV] max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=400, score=0.790, total=   0.6s\n",
      "[CV] max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=400, score=0.857, total=   0.6s\n",
      "[CV] max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=400, score=0.867, total=   0.6s\n",
      "[CV] max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200, score=0.743, total=   0.3s\n",
      "[CV] max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200, score=0.838, total=   0.3s\n",
      "[CV] max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200, score=0.800, total=   0.3s\n",
      "[CV] max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200, score=0.867, total=   0.3s\n",
      "[CV] max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200, score=0.857, total=   0.3s\n",
      "[CV] max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=400, score=0.743, total=   0.6s\n",
      "[CV] max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=400, score=0.857, total=   0.6s\n",
      "[CV] max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=400, score=0.781, total=   0.6s\n",
      "[CV] max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=400, score=0.857, total=   0.6s\n",
      "[CV] max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=400, score=0.857, total=   0.6s\n",
      "[CV] max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200, score=0.752, total=   0.3s\n",
      "[CV] max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200, score=0.857, total=   0.3s\n",
      "[CV] max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200, score=0.800, total=   0.3s\n",
      "[CV] max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200, score=0.876, total=   0.3s\n",
      "[CV] max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200, score=0.848, total=   0.3s\n",
      "[CV] max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=400, score=0.733, total=   0.6s\n",
      "[CV] max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=400, score=0.876, total=   0.6s\n",
      "[CV] max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=400, score=0.790, total=   0.6s\n",
      "[CV] max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=400, score=0.876, total=   0.6s\n",
      "[CV] max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=400, score=0.848, total=   0.6s\n",
      "[CV] max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200, score=0.762, total=   0.3s\n",
      "[CV] max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200, score=0.838, total=   0.3s\n",
      "[CV] max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200, score=0.790, total=   0.3s\n",
      "[CV] max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200, score=0.848, total=   0.3s\n",
      "[CV] max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200, score=0.857, total=   0.3s\n",
      "[CV] max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=400, score=0.733, total=   0.6s\n",
      "[CV] max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=400, score=0.838, total=   0.6s\n",
      "[CV] max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=400, score=0.800, total=   0.6s\n",
      "[CV] max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=400, score=0.876, total=   0.6s\n",
      "[CV] max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=400, score=0.857, total=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:   54.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(n_estimators=200),\n",
       "             param_grid={'max_depth': [10, 20, None],\n",
       "                         'min_samples_leaf': [1, 2],\n",
       "                         'min_samples_split': [2, 5],\n",
       "                         'n_estimators': [200, 400]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "0.8304761904761904\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_scaler = StandardScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1, Train/Test Score: 1.000/0.709\n",
      "k: 3, Train/Test Score: 0.851/0.697\n",
      "k: 5, Train/Test Score: 0.821/0.726\n",
      "k: 7, Train/Test Score: 0.813/0.726\n",
      "k: 9, Train/Test Score: 0.813/0.709\n",
      "k: 11, Train/Test Score: 0.804/0.743\n",
      "k: 13, Train/Test Score: 0.810/0.743\n",
      "k: 15, Train/Test Score: 0.802/0.749\n",
      "k: 17, Train/Test Score: 0.796/0.754\n",
      "k: 19, Train/Test Score: 0.790/0.743\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 20, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    train_score = knn.score(X_train_scaled, y_train)\n",
    "    test_score = knn.score(X_test_scaled, y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")\n",
    "    \n",
    "    \n",
    "plt.plot(range(1, 20, 2), train_scores, marker='o')\n",
    "plt.plot(range(1, 20, 2), test_scores, marker=\"x\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing accuracy Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=13 Test Acc: 0.743\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=13)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "print('k=13 Test Acc: %.3f' % knn.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 12) (700,)\n"
     ]
    }
   ],
   "source": [
    "X = cleaned_data.drop(\"secondary_genres\", axis=1)\n",
    "y = cleaned_data[\"secondary_genres\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC \n",
    "model = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_Scaler=MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_Scaler.transform(X_train)\n",
    "X_test_scaled = X_Scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 615,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.820952380952381\n",
      "Testing Data Score: 0.8114285714285714\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {model.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {model.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearchCV model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [1, 5, 10],\n",
    "              'gamma': [0.0001, 0.001, 0.01]}\n",
    "grid = GridSearchCV(model, param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0001, score=0.752, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0001, score=0.819, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0001, score=0.695, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0001, score=0.800, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0001, score=0.810, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.752, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.819, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.695, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.800, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.810, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ..................... C=1, gamma=0.01, score=0.752, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ..................... C=1, gamma=0.01, score=0.819, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ..................... C=1, gamma=0.01, score=0.695, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ..................... C=1, gamma=0.01, score=0.800, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ..................... C=1, gamma=0.01, score=0.810, total=   0.0s\n",
      "[CV] C=5, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0001, score=0.771, total=   0.0s\n",
      "[CV] C=5, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0001, score=0.810, total=   0.0s\n",
      "[CV] C=5, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0001, score=0.743, total=   0.0s\n",
      "[CV] C=5, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0001, score=0.800, total=   0.0s\n",
      "[CV] C=5, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0001, score=0.810, total=   0.0s\n",
      "[CV] C=5, gamma=0.001 ................................................\n",
      "[CV] .................... C=5, gamma=0.001, score=0.771, total=   0.0s\n",
      "[CV] C=5, gamma=0.001 ................................................\n",
      "[CV] .................... C=5, gamma=0.001, score=0.810, total=   0.0s\n",
      "[CV] C=5, gamma=0.001 ................................................\n",
      "[CV] .................... C=5, gamma=0.001, score=0.743, total=   0.0s\n",
      "[CV] C=5, gamma=0.001 ................................................\n",
      "[CV] .................... C=5, gamma=0.001, score=0.800, total=   0.0s\n",
      "[CV] C=5, gamma=0.001 ................................................\n",
      "[CV] .................... C=5, gamma=0.001, score=0.810, total=   0.0s\n",
      "[CV] C=5, gamma=0.01 .................................................\n",
      "[CV] ..................... C=5, gamma=0.01, score=0.771, total=   0.0s\n",
      "[CV] C=5, gamma=0.01 .................................................\n",
      "[CV] ..................... C=5, gamma=0.01, score=0.810, total=   0.0s\n",
      "[CV] C=5, gamma=0.01 .................................................\n",
      "[CV] ..................... C=5, gamma=0.01, score=0.743, total=   0.0s\n",
      "[CV] C=5, gamma=0.01 .................................................\n",
      "[CV] ..................... C=5, gamma=0.01, score=0.800, total=   0.0s\n",
      "[CV] C=5, gamma=0.01 .................................................\n",
      "[CV] ..................... C=5, gamma=0.01, score=0.810, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=0.771, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=0.810, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=0.743, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=0.810, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=0.800, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=10, gamma=0.001, score=0.771, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.810, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.743, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.810, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.800, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] .................... C=10, gamma=0.01, score=0.771, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] .................... C=10, gamma=0.01, score=0.810, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] .................... C=10, gamma=0.01, score=0.743, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] .................... C=10, gamma=0.01, score=0.810, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] .................... C=10, gamma=0.01, score=0.800, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(kernel='linear'),\n",
       "             param_grid={'C': [1, 5, 10], 'gamma': [0.0001, 0.001, 0.01]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 5, 'gamma': 0.0001}\n",
      "0.7866666666666667\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 12) (700,)\n"
     ]
    }
   ],
   "source": [
    "X = cleaned_data.drop(\"secondary_genres\", axis=1)\n",
    "y = cleaned_data[\"secondary_genres\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=12))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_36 (Dense)             (None, 100)               1300      \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 7)                 707       \n",
      "=================================================================\n",
      "Total params: 12,107\n",
      "Trainable params: 12,107\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 525 samples\n",
      "Epoch 1/60\n",
      "525/525 - 0s - loss: 1.8699 - accuracy: 0.3314\n",
      "Epoch 2/60\n",
      "525/525 - 0s - loss: 1.6815 - accuracy: 0.5048\n",
      "Epoch 3/60\n",
      "525/525 - 0s - loss: 1.4630 - accuracy: 0.5410\n",
      "Epoch 4/60\n",
      "525/525 - 0s - loss: 1.2658 - accuracy: 0.5905\n",
      "Epoch 5/60\n",
      "525/525 - 0s - loss: 1.1106 - accuracy: 0.6667\n",
      "Epoch 6/60\n",
      "525/525 - 0s - loss: 1.0070 - accuracy: 0.6971\n",
      "Epoch 7/60\n",
      "525/525 - 0s - loss: 0.9164 - accuracy: 0.7086\n",
      "Epoch 8/60\n",
      "525/525 - 0s - loss: 0.8529 - accuracy: 0.7143\n",
      "Epoch 9/60\n",
      "525/525 - 0s - loss: 0.8162 - accuracy: 0.7276\n",
      "Epoch 10/60\n",
      "525/525 - 0s - loss: 0.7758 - accuracy: 0.7390\n",
      "Epoch 11/60\n",
      "525/525 - 0s - loss: 0.7468 - accuracy: 0.7448\n",
      "Epoch 12/60\n",
      "525/525 - 0s - loss: 0.7198 - accuracy: 0.7543\n",
      "Epoch 13/60\n",
      "525/525 - 0s - loss: 0.7007 - accuracy: 0.7752\n",
      "Epoch 14/60\n",
      "525/525 - 0s - loss: 0.6915 - accuracy: 0.7600\n",
      "Epoch 15/60\n",
      "525/525 - 0s - loss: 0.6713 - accuracy: 0.7695\n",
      "Epoch 16/60\n",
      "525/525 - 0s - loss: 0.6620 - accuracy: 0.7771\n",
      "Epoch 17/60\n",
      "525/525 - 0s - loss: 0.6592 - accuracy: 0.7810\n",
      "Epoch 18/60\n",
      "525/525 - 0s - loss: 0.6410 - accuracy: 0.8038\n",
      "Epoch 19/60\n",
      "525/525 - 0s - loss: 0.6287 - accuracy: 0.7848\n",
      "Epoch 20/60\n",
      "525/525 - 0s - loss: 0.6285 - accuracy: 0.7981\n",
      "Epoch 21/60\n",
      "525/525 - 0s - loss: 0.6166 - accuracy: 0.8000\n",
      "Epoch 22/60\n",
      "525/525 - 0s - loss: 0.6113 - accuracy: 0.8095\n",
      "Epoch 23/60\n",
      "525/525 - 0s - loss: 0.6067 - accuracy: 0.8076\n",
      "Epoch 24/60\n",
      "525/525 - 0s - loss: 0.6000 - accuracy: 0.7771\n",
      "Epoch 25/60\n",
      "525/525 - 0s - loss: 0.5833 - accuracy: 0.8133\n",
      "Epoch 26/60\n",
      "525/525 - 0s - loss: 0.5841 - accuracy: 0.8210\n",
      "Epoch 27/60\n",
      "525/525 - 0s - loss: 0.5853 - accuracy: 0.8133\n",
      "Epoch 28/60\n",
      "525/525 - 0s - loss: 0.5724 - accuracy: 0.8171\n",
      "Epoch 29/60\n",
      "525/525 - 0s - loss: 0.5699 - accuracy: 0.8095\n",
      "Epoch 30/60\n",
      "525/525 - 0s - loss: 0.5645 - accuracy: 0.8133\n",
      "Epoch 31/60\n",
      "525/525 - 0s - loss: 0.5627 - accuracy: 0.8114\n",
      "Epoch 32/60\n",
      "525/525 - 0s - loss: 0.5520 - accuracy: 0.8171\n",
      "Epoch 33/60\n",
      "525/525 - 0s - loss: 0.5455 - accuracy: 0.8305\n",
      "Epoch 34/60\n",
      "525/525 - 0s - loss: 0.5420 - accuracy: 0.8190\n",
      "Epoch 35/60\n",
      "525/525 - 0s - loss: 0.5409 - accuracy: 0.8267\n",
      "Epoch 36/60\n",
      "525/525 - 0s - loss: 0.5464 - accuracy: 0.8343\n",
      "Epoch 37/60\n",
      "525/525 - 0s - loss: 0.5447 - accuracy: 0.8095\n",
      "Epoch 38/60\n",
      "525/525 - 0s - loss: 0.5367 - accuracy: 0.8248\n",
      "Epoch 39/60\n",
      "525/525 - 0s - loss: 0.5285 - accuracy: 0.8267\n",
      "Epoch 40/60\n",
      "525/525 - 0s - loss: 0.5300 - accuracy: 0.8210\n",
      "Epoch 41/60\n",
      "525/525 - 0s - loss: 0.5315 - accuracy: 0.8324\n",
      "Epoch 42/60\n",
      "525/525 - 0s - loss: 0.5148 - accuracy: 0.8286\n",
      "Epoch 43/60\n",
      "525/525 - 0s - loss: 0.5024 - accuracy: 0.8381\n",
      "Epoch 44/60\n",
      "525/525 - 0s - loss: 0.5044 - accuracy: 0.8381\n",
      "Epoch 45/60\n",
      "525/525 - 0s - loss: 0.5037 - accuracy: 0.8381\n",
      "Epoch 46/60\n",
      "525/525 - 0s - loss: 0.5063 - accuracy: 0.8419\n",
      "Epoch 47/60\n",
      "525/525 - 0s - loss: 0.5010 - accuracy: 0.8362\n",
      "Epoch 48/60\n",
      "525/525 - 0s - loss: 0.4900 - accuracy: 0.8476\n",
      "Epoch 49/60\n",
      "525/525 - 0s - loss: 0.4981 - accuracy: 0.8400\n",
      "Epoch 50/60\n",
      "525/525 - 0s - loss: 0.4921 - accuracy: 0.8419\n",
      "Epoch 51/60\n",
      "525/525 - 0s - loss: 0.4854 - accuracy: 0.8381\n",
      "Epoch 52/60\n",
      "525/525 - 0s - loss: 0.4761 - accuracy: 0.8457\n",
      "Epoch 53/60\n",
      "525/525 - 0s - loss: 0.4736 - accuracy: 0.8400\n",
      "Epoch 54/60\n",
      "525/525 - 0s - loss: 0.4824 - accuracy: 0.8400\n",
      "Epoch 55/60\n",
      "525/525 - 0s - loss: 0.4839 - accuracy: 0.8476\n",
      "Epoch 56/60\n",
      "525/525 - 0s - loss: 0.4779 - accuracy: 0.8457\n",
      "Epoch 57/60\n",
      "525/525 - 0s - loss: 0.4597 - accuracy: 0.8648\n",
      "Epoch 58/60\n",
      "525/525 - 0s - loss: 0.4666 - accuracy: 0.8495\n",
      "Epoch 59/60\n",
      "525/525 - 0s - loss: 0.4655 - accuracy: 0.8533\n",
      "Epoch 60/60\n",
      "525/525 - 0s - loss: 0.4576 - accuracy: 0.8571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1758c115eb8>"
      ]
     },
     "execution_count": 627,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/175 - 0s - loss: 0.8376 - accuracy: 0.7829\n",
      "Normal Neural Network - Loss: 0.837621100970677, Accuracy: 0.7828571200370789\n"
     ]
    }
   ],
   "source": [
    " model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_predictions = model.predict_classes(X_test_scaled[:5])\n",
    "prediction_labels = label_encoder.inverse_transform(encoded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classes: ['cool jazz' 'cool jazz' 'texas country' 'cool jazz' 'trap']\n",
      "Actual Labels: ['cool jazz', 'cool jazz', 'texas country', 'cool jazz', 'texas country']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Predicted classes: {prediction_labels}\")\n",
    "print(f\"Actual Labels: {list(y_test[:5])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cool jazz</td>\n",
       "      <td>cool jazz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cool jazz</td>\n",
       "      <td>cool jazz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>texas country</td>\n",
       "      <td>texas country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cool jazz</td>\n",
       "      <td>cool jazz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trap</td>\n",
       "      <td>texas country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>texas country</td>\n",
       "      <td>texas country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>performance</td>\n",
       "      <td>performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>texas country</td>\n",
       "      <td>electro house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>cool jazz</td>\n",
       "      <td>cool jazz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>trap</td>\n",
       "      <td>trap</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Prediction         Actual\n",
       "0        cool jazz      cool jazz\n",
       "1        cool jazz      cool jazz\n",
       "2    texas country  texas country\n",
       "3        cool jazz      cool jazz\n",
       "4             trap  texas country\n",
       "..             ...            ...\n",
       "170  texas country  texas country\n",
       "171    performance    performance\n",
       "172  texas country  electro house\n",
       "173      cool jazz      cool jazz\n",
       "174           trap           trap\n",
       "\n",
       "[175 rows x 2 columns]"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"Prediction\": predictions, \"Actual\": y_test}).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
