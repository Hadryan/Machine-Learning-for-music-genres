{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression for 10 Primary Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>artists</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>popularity</th>\n",
       "      <th>key</th>\n",
       "      <th>mode</th>\n",
       "      <th>count</th>\n",
       "      <th>genres</th>\n",
       "      <th>new_genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26807</td>\n",
       "      <td>Yhung T.O.</td>\n",
       "      <td>0.302000</td>\n",
       "      <td>0.811</td>\n",
       "      <td>206593.0</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0865</td>\n",
       "      <td>-7.003</td>\n",
       "      <td>0.180</td>\n",
       "      <td>96.993</td>\n",
       "      <td>0.546</td>\n",
       "      <td>60.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>['cali rap', 'west coast trap']</td>\n",
       "      <td>rap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9250</td>\n",
       "      <td>Grieves</td>\n",
       "      <td>0.042100</td>\n",
       "      <td>0.592</td>\n",
       "      <td>185373.0</td>\n",
       "      <td>0.509</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0814</td>\n",
       "      <td>-6.685</td>\n",
       "      <td>0.375</td>\n",
       "      <td>180.121</td>\n",
       "      <td>0.631</td>\n",
       "      <td>44.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>['abstract hip hop', 'indie pop rap', 'undergr...</td>\n",
       "      <td>rap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15653</td>\n",
       "      <td>Mark Battles</td>\n",
       "      <td>0.209000</td>\n",
       "      <td>0.745</td>\n",
       "      <td>185487.0</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5100</td>\n",
       "      <td>-7.212</td>\n",
       "      <td>0.184</td>\n",
       "      <td>94.002</td>\n",
       "      <td>0.480</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>['canadian hip hop', 'deep underground hip hop...</td>\n",
       "      <td>rap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5271</td>\n",
       "      <td>DJ Jazzy Jeff</td>\n",
       "      <td>0.029000</td>\n",
       "      <td>0.782</td>\n",
       "      <td>250200.0</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1970</td>\n",
       "      <td>-8.154</td>\n",
       "      <td>0.365</td>\n",
       "      <td>95.116</td>\n",
       "      <td>0.487</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>['gangster rap', 'hip hop', 'old school hip ho...</td>\n",
       "      <td>rap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25090</td>\n",
       "      <td>Tion Wayne</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.572</td>\n",
       "      <td>169355.0</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.1290</td>\n",
       "      <td>-8.054</td>\n",
       "      <td>0.243</td>\n",
       "      <td>100.453</td>\n",
       "      <td>0.704</td>\n",
       "      <td>77.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>['london rap', 'uk hip hop']</td>\n",
       "      <td>rap</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id        artists  acousticness  danceability  duration_ms  energy  \\\n",
       "0  26807     Yhung T.O.      0.302000         0.811     206593.0   0.574   \n",
       "1   9250        Grieves      0.042100         0.592     185373.0   0.509   \n",
       "2  15653   Mark Battles      0.209000         0.745     185487.0   0.741   \n",
       "3   5271  DJ Jazzy Jeff      0.029000         0.782     250200.0   0.639   \n",
       "4  25090     Tion Wayne      0.000415         0.572     169355.0   0.519   \n",
       "\n",
       "   instrumentalness  liveness  loudness  speechiness    tempo  valence  \\\n",
       "0          0.000000    0.0865    -7.003        0.180   96.993    0.546   \n",
       "1          0.000000    0.0814    -6.685        0.375  180.121    0.631   \n",
       "2          0.000000    0.5100    -7.212        0.184   94.002    0.480   \n",
       "3          0.000000    0.1970    -8.154        0.365   95.116    0.487   \n",
       "4          0.000023    0.1290    -8.054        0.243  100.453    0.704   \n",
       "\n",
       "   popularity  key  mode  count  \\\n",
       "0        60.0    5     0      1   \n",
       "1        44.0   11     1      2   \n",
       "2        57.0    2     1      2   \n",
       "3        47.0    1     1      1   \n",
       "4        77.0   10     0      2   \n",
       "\n",
       "                                              genres new_genres  \n",
       "0                    ['cali rap', 'west coast trap']        rap  \n",
       "1  ['abstract hip hop', 'indie pop rap', 'undergr...        rap  \n",
       "2  ['canadian hip hop', 'deep underground hip hop...        rap  \n",
       "3  ['gangster rap', 'hip hop', 'old school hip ho...        rap  \n",
       "4                       ['london rap', 'uk hip hop']        rap  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(os.path.join('Data', 'allgenres.csv'))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>key</th>\n",
       "      <th>mode</th>\n",
       "      <th>new_genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.302000</td>\n",
       "      <td>0.811</td>\n",
       "      <td>206593.0</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0865</td>\n",
       "      <td>-7.003</td>\n",
       "      <td>0.180</td>\n",
       "      <td>96.993</td>\n",
       "      <td>0.546</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>rap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.042100</td>\n",
       "      <td>0.592</td>\n",
       "      <td>185373.0</td>\n",
       "      <td>0.509</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0814</td>\n",
       "      <td>-6.685</td>\n",
       "      <td>0.375</td>\n",
       "      <td>180.121</td>\n",
       "      <td>0.631</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>rap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.209000</td>\n",
       "      <td>0.745</td>\n",
       "      <td>185487.0</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5100</td>\n",
       "      <td>-7.212</td>\n",
       "      <td>0.184</td>\n",
       "      <td>94.002</td>\n",
       "      <td>0.480</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>rap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.029000</td>\n",
       "      <td>0.782</td>\n",
       "      <td>250200.0</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1970</td>\n",
       "      <td>-8.154</td>\n",
       "      <td>0.365</td>\n",
       "      <td>95.116</td>\n",
       "      <td>0.487</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>rap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.572</td>\n",
       "      <td>169355.0</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.1290</td>\n",
       "      <td>-8.054</td>\n",
       "      <td>0.243</td>\n",
       "      <td>100.453</td>\n",
       "      <td>0.704</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>rap</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acousticness  danceability  duration_ms  energy  instrumentalness  \\\n",
       "0      0.302000         0.811     206593.0   0.574          0.000000   \n",
       "1      0.042100         0.592     185373.0   0.509          0.000000   \n",
       "2      0.209000         0.745     185487.0   0.741          0.000000   \n",
       "3      0.029000         0.782     250200.0   0.639          0.000000   \n",
       "4      0.000415         0.572     169355.0   0.519          0.000023   \n",
       "\n",
       "   liveness  loudness  speechiness    tempo  valence  key  mode new_genres  \n",
       "0    0.0865    -7.003        0.180   96.993    0.546    5     0        rap  \n",
       "1    0.0814    -6.685        0.375  180.121    0.631   11     1        rap  \n",
       "2    0.5100    -7.212        0.184   94.002    0.480    2     1        rap  \n",
       "3    0.1970    -8.154        0.365   95.116    0.487    1     1        rap  \n",
       "4    0.1290    -8.054        0.243  100.453    0.704   10     0        rap  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data=data.drop([\"id\",\"artists\",\"count\",\"genres\",\"popularity\",\"genres\",],axis=1)\n",
    "cleaned_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 12) (1000,)\n"
     ]
    }
   ],
   "source": [
    "X = cleaned_data.drop(\"new_genres\", axis=1)\n",
    "y = cleaned_data[\"new_genres\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale your data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_Scaler=MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_Scaler.transform(X_train)\n",
    "X_test_scaled = X_Scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(penalty='l2',C=10, solver= 'newton-cg')\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.5493333333333333\n",
      "Testing Data Score: 0.472\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {classifier.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 Predictions:   ['metal' 'country' 'edm' 'alternative' 'christian' 'classical' 'edm'\n",
      " 'country' 'r&b' 'rap']\n",
      "First 10 Actual labels: ['alternative', 'latin', 'r&b', 'edm', 'christian', 'jazz', 'christian', 'latin', 'edm', 'rap']\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test_scaled)\n",
    "print(f\"First 10 Predictions:   {predictions[:10]}\")\n",
    "print(f\"First 10 Actual labels: {y_test[:10].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>metal</td>\n",
       "      <td>alternative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>country</td>\n",
       "      <td>latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>edm</td>\n",
       "      <td>r&amp;b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alternative</td>\n",
       "      <td>edm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>christian</td>\n",
       "      <td>christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>edm</td>\n",
       "      <td>edm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>country</td>\n",
       "      <td>latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>r&amp;b</td>\n",
       "      <td>r&amp;b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>classical</td>\n",
       "      <td>classical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>edm</td>\n",
       "      <td>alternative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Prediction       Actual\n",
       "0          metal  alternative\n",
       "1        country        latin\n",
       "2            edm          r&b\n",
       "3    alternative          edm\n",
       "4      christian    christian\n",
       "..           ...          ...\n",
       "245          edm          edm\n",
       "246      country        latin\n",
       "247          r&b          r&b\n",
       "248    classical    classical\n",
       "249          edm  alternative\n",
       "\n",
       "[250 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"Prediction\": predictions, \"Actual\": y_test}).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "plot_confusion_matrix(classifier, X_test_scaled, y_test, cmap=plt.cm.Blues)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['C', 'class_weight', 'dual', 'fit_intercept', 'intercept_scaling', 'l1_ratio', 'max_iter', 'multi_class', 'n_jobs', 'penalty', 'random_state', 'solver', 'tol', 'verbose', 'warm_start'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'penalty': ['l1','l2'],\n",
    "              'C': [100, 10, 1.0, 0.1, 0.01,0.001,0.0001,0.0005,0.005],\n",
    "             'solver' : ['newton-cg', 'lbfgs', 'liblinear']}\n",
    "grid = GridSearchCV(classifier, param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "[CV] C=100, penalty=l1, solver=newton-cg .............................\n",
      "[CV] ... C=100, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=100, penalty=l1, solver=newton-cg .............................\n",
      "[CV] ... C=100, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=100, penalty=l1, solver=newton-cg .............................\n",
      "[CV] ... C=100, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=100, penalty=l1, solver=newton-cg .............................\n",
      "[CV] ... C=100, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=100, penalty=l1, solver=newton-cg .............................\n",
      "[CV] ... C=100, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=100, penalty=l1, solver=lbfgs .................................\n",
      "[CV] ....... C=100, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=100, penalty=l1, solver=lbfgs .................................\n",
      "[CV] ....... C=100, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=100, penalty=l1, solver=lbfgs .................................\n",
      "[CV] ....... C=100, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=100, penalty=l1, solver=lbfgs .................................\n",
      "[CV] ....... C=100, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=100, penalty=l1, solver=lbfgs .................................\n",
      "[CV] ....... C=100, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=100, penalty=l1, solver=liblinear .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\bvera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "C:\\Users\\bvera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . C=100, penalty=l1, solver=liblinear, score=0.553, total=   0.2s\n",
      "[CV] C=100, penalty=l1, solver=liblinear .............................\n",
      "[CV] . C=100, penalty=l1, solver=liblinear, score=0.547, total=   0.2s\n",
      "[CV] C=100, penalty=l1, solver=liblinear .............................\n",
      "[CV] . C=100, penalty=l1, solver=liblinear, score=0.500, total=   0.2s\n",
      "[CV] C=100, penalty=l1, solver=liblinear .............................\n",
      "[CV] . C=100, penalty=l1, solver=liblinear, score=0.467, total=   0.2s\n",
      "[CV] C=100, penalty=l1, solver=liblinear .............................\n",
      "[CV] . C=100, penalty=l1, solver=liblinear, score=0.527, total=   0.2s\n",
      "[CV] C=100, penalty=l2, solver=newton-cg .............................\n",
      "[CV] . C=100, penalty=l2, solver=newton-cg, score=0.540, total=   0.0s\n",
      "[CV] C=100, penalty=l2, solver=newton-cg .............................\n",
      "[CV] . C=100, penalty=l2, solver=newton-cg, score=0.527, total=   0.0s\n",
      "[CV] C=100, penalty=l2, solver=newton-cg .............................\n",
      "[CV] . C=100, penalty=l2, solver=newton-cg, score=0.487, total=   0.0s\n",
      "[CV] C=100, penalty=l2, solver=newton-cg .............................\n",
      "[CV] . C=100, penalty=l2, solver=newton-cg, score=0.447, total=   0.0s\n",
      "[CV] C=100, penalty=l2, solver=newton-cg .............................\n",
      "[CV] . C=100, penalty=l2, solver=newton-cg, score=0.520, total=   0.0s\n",
      "[CV] C=100, penalty=l2, solver=lbfgs .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bvera\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\bvera\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\bvera\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\bvera\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\bvera\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... C=100, penalty=l2, solver=lbfgs, score=0.540, total=   0.0s\n",
      "[CV] C=100, penalty=l2, solver=lbfgs .................................\n",
      "[CV] ..... C=100, penalty=l2, solver=lbfgs, score=0.533, total=   0.0s\n",
      "[CV] C=100, penalty=l2, solver=lbfgs .................................\n",
      "[CV] ..... C=100, penalty=l2, solver=lbfgs, score=0.480, total=   0.0s\n",
      "[CV] C=100, penalty=l2, solver=lbfgs .................................\n",
      "[CV] ..... C=100, penalty=l2, solver=lbfgs, score=0.460, total=   0.0s\n",
      "[CV] C=100, penalty=l2, solver=lbfgs .................................\n",
      "[CV] ..... C=100, penalty=l2, solver=lbfgs, score=0.520, total=   0.0s\n",
      "[CV] C=100, penalty=l2, solver=liblinear .............................\n",
      "[CV] . C=100, penalty=l2, solver=liblinear, score=0.567, total=   0.0s\n",
      "[CV] C=100, penalty=l2, solver=liblinear .............................\n",
      "[CV] . C=100, penalty=l2, solver=liblinear, score=0.540, total=   0.0s\n",
      "[CV] C=100, penalty=l2, solver=liblinear .............................\n",
      "[CV] . C=100, penalty=l2, solver=liblinear, score=0.500, total=   0.0s\n",
      "[CV] C=100, penalty=l2, solver=liblinear .............................\n",
      "[CV] . C=100, penalty=l2, solver=liblinear, score=0.460, total=   0.0s\n",
      "[CV] C=100, penalty=l2, solver=liblinear .............................\n",
      "[CV] . C=100, penalty=l2, solver=liblinear, score=0.527, total=   0.0s\n",
      "[CV] C=10, penalty=l1, solver=newton-cg ..............................\n",
      "[CV] .... C=10, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=l1, solver=newton-cg ..............................\n",
      "[CV] .... C=10, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=l1, solver=newton-cg ..............................\n",
      "[CV] .... C=10, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=l1, solver=newton-cg ..............................\n",
      "[CV] .... C=10, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=l1, solver=newton-cg ..............................\n",
      "[CV] .... C=10, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=l1, solver=lbfgs ..................................\n",
      "[CV] ........ C=10, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=l1, solver=lbfgs ..................................\n",
      "[CV] ........ C=10, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=l1, solver=lbfgs ..................................\n",
      "[CV] ........ C=10, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=l1, solver=lbfgs ..................................\n",
      "[CV] ........ C=10, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=l1, solver=lbfgs ..................................\n",
      "[CV] ........ C=10, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=l1, solver=liblinear ..............................\n",
      "[CV] .. C=10, penalty=l1, solver=liblinear, score=0.567, total=   0.2s\n",
      "[CV] C=10, penalty=l1, solver=liblinear ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bvera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\bvera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. C=10, penalty=l1, solver=liblinear, score=0.547, total=   0.2s\n",
      "[CV] C=10, penalty=l1, solver=liblinear ..............................\n",
      "[CV] .. C=10, penalty=l1, solver=liblinear, score=0.507, total=   0.2s\n",
      "[CV] C=10, penalty=l1, solver=liblinear ..............................\n",
      "[CV] .. C=10, penalty=l1, solver=liblinear, score=0.460, total=   0.2s\n",
      "[CV] C=10, penalty=l1, solver=liblinear ..............................\n",
      "[CV] .. C=10, penalty=l1, solver=liblinear, score=0.513, total=   0.1s\n",
      "[CV] C=10, penalty=l2, solver=newton-cg ..............................\n",
      "[CV] .. C=10, penalty=l2, solver=newton-cg, score=0.520, total=   0.0s\n",
      "[CV] C=10, penalty=l2, solver=newton-cg ..............................\n",
      "[CV] .. C=10, penalty=l2, solver=newton-cg, score=0.527, total=   0.0s\n",
      "[CV] C=10, penalty=l2, solver=newton-cg ..............................\n",
      "[CV] .. C=10, penalty=l2, solver=newton-cg, score=0.487, total=   0.0s\n",
      "[CV] C=10, penalty=l2, solver=newton-cg ..............................\n",
      "[CV] .. C=10, penalty=l2, solver=newton-cg, score=0.453, total=   0.0s\n",
      "[CV] C=10, penalty=l2, solver=newton-cg ..............................\n",
      "[CV] .. C=10, penalty=l2, solver=newton-cg, score=0.520, total=   0.0s\n",
      "[CV] C=10, penalty=l2, solver=lbfgs ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bvera\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\bvera\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\bvera\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\bvera\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\bvera\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... C=10, penalty=l2, solver=lbfgs, score=0.513, total=   0.0s\n",
      "[CV] C=10, penalty=l2, solver=lbfgs ..................................\n",
      "[CV] ...... C=10, penalty=l2, solver=lbfgs, score=0.520, total=   0.0s\n",
      "[CV] C=10, penalty=l2, solver=lbfgs ..................................\n",
      "[CV] ...... C=10, penalty=l2, solver=lbfgs, score=0.487, total=   0.0s\n",
      "[CV] C=10, penalty=l2, solver=lbfgs ..................................\n",
      "[CV] ...... C=10, penalty=l2, solver=lbfgs, score=0.453, total=   0.0s\n",
      "[CV] C=10, penalty=l2, solver=lbfgs ..................................\n",
      "[CV] ...... C=10, penalty=l2, solver=lbfgs, score=0.520, total=   0.0s\n",
      "[CV] C=10, penalty=l2, solver=liblinear ..............................\n",
      "[CV] .. C=10, penalty=l2, solver=liblinear, score=0.560, total=   0.0s\n",
      "[CV] C=10, penalty=l2, solver=liblinear ..............................\n",
      "[CV] .. C=10, penalty=l2, solver=liblinear, score=0.540, total=   0.0s\n",
      "[CV] C=10, penalty=l2, solver=liblinear ..............................\n",
      "[CV] .. C=10, penalty=l2, solver=liblinear, score=0.500, total=   0.0s\n",
      "[CV] C=10, penalty=l2, solver=liblinear ..............................\n",
      "[CV] .. C=10, penalty=l2, solver=liblinear, score=0.460, total=   0.0s\n",
      "[CV] C=10, penalty=l2, solver=liblinear ..............................\n",
      "[CV] .. C=10, penalty=l2, solver=liblinear, score=0.513, total=   0.0s\n",
      "[CV] C=1.0, penalty=l1, solver=newton-cg .............................\n",
      "[CV] ... C=1.0, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=1.0, penalty=l1, solver=newton-cg .............................\n",
      "[CV] ... C=1.0, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=1.0, penalty=l1, solver=newton-cg .............................\n",
      "[CV] ... C=1.0, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=1.0, penalty=l1, solver=newton-cg .............................\n",
      "[CV] ... C=1.0, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=1.0, penalty=l1, solver=newton-cg .............................\n",
      "[CV] ... C=1.0, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=1.0, penalty=l1, solver=lbfgs .................................\n",
      "[CV] ....... C=1.0, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=1.0, penalty=l1, solver=lbfgs .................................\n",
      "[CV] ....... C=1.0, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=1.0, penalty=l1, solver=lbfgs .................................\n",
      "[CV] ....... C=1.0, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=1.0, penalty=l1, solver=lbfgs .................................\n",
      "[CV] ....... C=1.0, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=1.0, penalty=l1, solver=lbfgs .................................\n",
      "[CV] ....... C=1.0, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=1.0, penalty=l1, solver=liblinear .............................\n",
      "[CV] . C=1.0, penalty=l1, solver=liblinear, score=0.500, total=   0.0s\n",
      "[CV] C=1.0, penalty=l1, solver=liblinear .............................\n",
      "[CV] . C=1.0, penalty=l1, solver=liblinear, score=0.540, total=   0.0s\n",
      "[CV] C=1.0, penalty=l1, solver=liblinear .............................\n",
      "[CV] . C=1.0, penalty=l1, solver=liblinear, score=0.553, total=   0.0s\n",
      "[CV] C=1.0, penalty=l1, solver=liblinear .............................\n",
      "[CV] . C=1.0, penalty=l1, solver=liblinear, score=0.473, total=   0.0s\n",
      "[CV] C=1.0, penalty=l1, solver=liblinear .............................\n",
      "[CV] . C=1.0, penalty=l1, solver=liblinear, score=0.487, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bvera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\bvera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=1.0, penalty=l2, solver=newton-cg .............................\n",
      "[CV] . C=1.0, penalty=l2, solver=newton-cg, score=0.507, total=   0.0s\n",
      "[CV] C=1.0, penalty=l2, solver=newton-cg .............................\n",
      "[CV] . C=1.0, penalty=l2, solver=newton-cg, score=0.507, total=   0.0s\n",
      "[CV] C=1.0, penalty=l2, solver=newton-cg .............................\n",
      "[CV] . C=1.0, penalty=l2, solver=newton-cg, score=0.513, total=   0.0s\n",
      "[CV] C=1.0, penalty=l2, solver=newton-cg .............................\n",
      "[CV] . C=1.0, penalty=l2, solver=newton-cg, score=0.467, total=   0.0s\n",
      "[CV] C=1.0, penalty=l2, solver=newton-cg .............................\n",
      "[CV] . C=1.0, penalty=l2, solver=newton-cg, score=0.480, total=   0.0s\n",
      "[CV] C=1.0, penalty=l2, solver=lbfgs .................................\n",
      "[CV] ..... C=1.0, penalty=l2, solver=lbfgs, score=0.507, total=   0.0s\n",
      "[CV] C=1.0, penalty=l2, solver=lbfgs .................................\n",
      "[CV] ..... C=1.0, penalty=l2, solver=lbfgs, score=0.507, total=   0.0s\n",
      "[CV] C=1.0, penalty=l2, solver=lbfgs .................................\n",
      "[CV] ..... C=1.0, penalty=l2, solver=lbfgs, score=0.513, total=   0.0s\n",
      "[CV] C=1.0, penalty=l2, solver=lbfgs .................................\n",
      "[CV] ..... C=1.0, penalty=l2, solver=lbfgs, score=0.467, total=   0.0s\n",
      "[CV] C=1.0, penalty=l2, solver=lbfgs .................................\n",
      "[CV] ..... C=1.0, penalty=l2, solver=lbfgs, score=0.480, total=   0.0s\n",
      "[CV] C=1.0, penalty=l2, solver=liblinear .............................\n",
      "[CV] . C=1.0, penalty=l2, solver=liblinear, score=0.500, total=   0.0s\n",
      "[CV] C=1.0, penalty=l2, solver=liblinear .............................\n",
      "[CV] . C=1.0, penalty=l2, solver=liblinear, score=0.493, total=   0.0s\n",
      "[CV] C=1.0, penalty=l2, solver=liblinear .............................\n",
      "[CV] . C=1.0, penalty=l2, solver=liblinear, score=0.527, total=   0.0s\n",
      "[CV] C=1.0, penalty=l2, solver=liblinear .............................\n",
      "[CV] . C=1.0, penalty=l2, solver=liblinear, score=0.487, total=   0.0s\n",
      "[CV] C=1.0, penalty=l2, solver=liblinear .............................\n",
      "[CV] . C=1.0, penalty=l2, solver=liblinear, score=0.473, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1, solver=newton-cg .............................\n",
      "[CV] ... C=0.1, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1, solver=newton-cg .............................\n",
      "[CV] ... C=0.1, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1, solver=newton-cg .............................\n",
      "[CV] ... C=0.1, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1, solver=newton-cg .............................\n",
      "[CV] ... C=0.1, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1, solver=newton-cg .............................\n",
      "[CV] ... C=0.1, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1, solver=lbfgs .................................\n",
      "[CV] ....... C=0.1, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1, solver=lbfgs .................................\n",
      "[CV] ....... C=0.1, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1, solver=lbfgs .................................\n",
      "[CV] ....... C=0.1, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1, solver=lbfgs .................................\n",
      "[CV] ....... C=0.1, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1, solver=lbfgs .................................\n",
      "[CV] ....... C=0.1, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1, solver=liblinear .............................\n",
      "[CV] . C=0.1, penalty=l1, solver=liblinear, score=0.367, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1, solver=liblinear .............................\n",
      "[CV] . C=0.1, penalty=l1, solver=liblinear, score=0.307, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1, solver=liblinear .............................\n",
      "[CV] . C=0.1, penalty=l1, solver=liblinear, score=0.327, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1, solver=liblinear .............................\n",
      "[CV] . C=0.1, penalty=l1, solver=liblinear, score=0.300, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bvera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\bvera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=0.1, penalty=l1, solver=liblinear .............................\n",
      "[CV] . C=0.1, penalty=l1, solver=liblinear, score=0.327, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2, solver=newton-cg .............................\n",
      "[CV] . C=0.1, penalty=l2, solver=newton-cg, score=0.453, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2, solver=newton-cg .............................\n",
      "[CV] . C=0.1, penalty=l2, solver=newton-cg, score=0.440, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2, solver=newton-cg .............................\n",
      "[CV] . C=0.1, penalty=l2, solver=newton-cg, score=0.433, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2, solver=newton-cg .............................\n",
      "[CV] . C=0.1, penalty=l2, solver=newton-cg, score=0.447, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2, solver=newton-cg .............................\n",
      "[CV] . C=0.1, penalty=l2, solver=newton-cg, score=0.393, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2, solver=lbfgs .................................\n",
      "[CV] ..... C=0.1, penalty=l2, solver=lbfgs, score=0.453, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2, solver=lbfgs .................................\n",
      "[CV] ..... C=0.1, penalty=l2, solver=lbfgs, score=0.440, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2, solver=lbfgs .................................\n",
      "[CV] ..... C=0.1, penalty=l2, solver=lbfgs, score=0.433, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2, solver=lbfgs .................................\n",
      "[CV] ..... C=0.1, penalty=l2, solver=lbfgs, score=0.447, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2, solver=lbfgs .................................\n",
      "[CV] ..... C=0.1, penalty=l2, solver=lbfgs, score=0.393, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2, solver=liblinear .............................\n",
      "[CV] . C=0.1, penalty=l2, solver=liblinear, score=0.440, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2, solver=liblinear .............................\n",
      "[CV] . C=0.1, penalty=l2, solver=liblinear, score=0.433, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2, solver=liblinear .............................\n",
      "[CV] . C=0.1, penalty=l2, solver=liblinear, score=0.427, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2, solver=liblinear .............................\n",
      "[CV] . C=0.1, penalty=l2, solver=liblinear, score=0.433, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2, solver=liblinear .............................\n",
      "[CV] . C=0.1, penalty=l2, solver=liblinear, score=0.407, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1, solver=newton-cg ............................\n",
      "[CV] .. C=0.01, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1, solver=newton-cg ............................\n",
      "[CV] .. C=0.01, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1, solver=newton-cg ............................\n",
      "[CV] .. C=0.01, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1, solver=newton-cg ............................\n",
      "[CV] .. C=0.01, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1, solver=newton-cg ............................\n",
      "[CV] .. C=0.01, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1, solver=lbfgs ................................\n",
      "[CV] ...... C=0.01, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1, solver=lbfgs ................................\n",
      "[CV] ...... C=0.01, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1, solver=lbfgs ................................\n",
      "[CV] ...... C=0.01, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1, solver=lbfgs ................................\n",
      "[CV] ...... C=0.01, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1, solver=lbfgs ................................\n",
      "[CV] ...... C=0.01, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1, solver=liblinear ............................\n",
      "[CV]  C=0.01, penalty=l1, solver=liblinear, score=0.107, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1, solver=liblinear ............................\n",
      "[CV]  C=0.01, penalty=l1, solver=liblinear, score=0.107, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1, solver=liblinear ............................\n",
      "[CV]  C=0.01, penalty=l1, solver=liblinear, score=0.107, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1, solver=liblinear ............................\n",
      "[CV]  C=0.01, penalty=l1, solver=liblinear, score=0.107, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1, solver=liblinear ............................\n",
      "[CV]  C=0.01, penalty=l1, solver=liblinear, score=0.100, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2, solver=newton-cg ............................\n",
      "[CV]  C=0.01, penalty=l2, solver=newton-cg, score=0.387, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2, solver=newton-cg ............................\n",
      "[CV]  C=0.01, penalty=l2, solver=newton-cg, score=0.313, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2, solver=newton-cg ............................\n",
      "[CV]  C=0.01, penalty=l2, solver=newton-cg, score=0.360, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2, solver=newton-cg ............................\n",
      "[CV]  C=0.01, penalty=l2, solver=newton-cg, score=0.360, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2, solver=newton-cg ............................\n",
      "[CV]  C=0.01, penalty=l2, solver=newton-cg, score=0.280, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2, solver=lbfgs ................................\n",
      "[CV] .... C=0.01, penalty=l2, solver=lbfgs, score=0.387, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2, solver=lbfgs ................................\n",
      "[CV] .... C=0.01, penalty=l2, solver=lbfgs, score=0.313, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2, solver=lbfgs ................................\n",
      "[CV] .... C=0.01, penalty=l2, solver=lbfgs, score=0.360, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2, solver=lbfgs ................................\n",
      "[CV] .... C=0.01, penalty=l2, solver=lbfgs, score=0.360, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2, solver=lbfgs ................................\n",
      "[CV] .... C=0.01, penalty=l2, solver=lbfgs, score=0.280, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2, solver=liblinear ............................\n",
      "[CV]  C=0.01, penalty=l2, solver=liblinear, score=0.353, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2, solver=liblinear ............................\n",
      "[CV]  C=0.01, penalty=l2, solver=liblinear, score=0.347, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2, solver=liblinear ............................\n",
      "[CV]  C=0.01, penalty=l2, solver=liblinear, score=0.353, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2, solver=liblinear ............................\n",
      "[CV]  C=0.01, penalty=l2, solver=liblinear, score=0.393, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2, solver=liblinear ............................\n",
      "[CV]  C=0.01, penalty=l2, solver=liblinear, score=0.347, total=   0.0s\n",
      "[CV] C=0.001, penalty=l1, solver=newton-cg ...........................\n",
      "[CV] . C=0.001, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=0.001, penalty=l1, solver=newton-cg ...........................\n",
      "[CV] . C=0.001, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=0.001, penalty=l1, solver=newton-cg ...........................\n",
      "[CV] . C=0.001, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=0.001, penalty=l1, solver=newton-cg ...........................\n",
      "[CV] . C=0.001, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=0.001, penalty=l1, solver=newton-cg ...........................\n",
      "[CV] . C=0.001, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=0.001, penalty=l1, solver=lbfgs ...............................\n",
      "[CV] ..... C=0.001, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=0.001, penalty=l1, solver=lbfgs ...............................\n",
      "[CV] ..... C=0.001, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=0.001, penalty=l1, solver=lbfgs ...............................\n",
      "[CV] ..... C=0.001, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=0.001, penalty=l1, solver=lbfgs ...............................\n",
      "[CV] ..... C=0.001, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=0.001, penalty=l1, solver=lbfgs ...............................\n",
      "[CV] ..... C=0.001, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=0.001, penalty=l1, solver=liblinear ...........................\n",
      "[CV]  C=0.001, penalty=l1, solver=liblinear, score=0.087, total=   0.0s\n",
      "[CV] C=0.001, penalty=l1, solver=liblinear ...........................\n",
      "[CV]  C=0.001, penalty=l1, solver=liblinear, score=0.093, total=   0.0s\n",
      "[CV] C=0.001, penalty=l1, solver=liblinear ...........................\n",
      "[CV]  C=0.001, penalty=l1, solver=liblinear, score=0.093, total=   0.0s\n",
      "[CV] C=0.001, penalty=l1, solver=liblinear ...........................\n",
      "[CV]  C=0.001, penalty=l1, solver=liblinear, score=0.093, total=   0.0s\n",
      "[CV] C=0.001, penalty=l1, solver=liblinear ...........................\n",
      "[CV]  C=0.001, penalty=l1, solver=liblinear, score=0.093, total=   0.0s\n",
      "[CV] C=0.001, penalty=l2, solver=newton-cg ...........................\n",
      "[CV]  C=0.001, penalty=l2, solver=newton-cg, score=0.133, total=   0.0s\n",
      "[CV] C=0.001, penalty=l2, solver=newton-cg ...........................\n",
      "[CV]  C=0.001, penalty=l2, solver=newton-cg, score=0.147, total=   0.0s\n",
      "[CV] C=0.001, penalty=l2, solver=newton-cg ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bvera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\bvera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\bvera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\bvera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.001, penalty=l2, solver=newton-cg, score=0.160, total=   0.0s\n",
      "[CV] C=0.001, penalty=l2, solver=newton-cg ...........................\n",
      "[CV]  C=0.001, penalty=l2, solver=newton-cg, score=0.127, total=   0.0s\n",
      "[CV] C=0.001, penalty=l2, solver=newton-cg ...........................\n",
      "[CV]  C=0.001, penalty=l2, solver=newton-cg, score=0.100, total=   0.0s\n",
      "[CV] C=0.001, penalty=l2, solver=lbfgs ...............................\n",
      "[CV] ... C=0.001, penalty=l2, solver=lbfgs, score=0.133, total=   0.0s\n",
      "[CV] C=0.001, penalty=l2, solver=lbfgs ...............................\n",
      "[CV] ... C=0.001, penalty=l2, solver=lbfgs, score=0.147, total=   0.0s\n",
      "[CV] C=0.001, penalty=l2, solver=lbfgs ...............................\n",
      "[CV] ... C=0.001, penalty=l2, solver=lbfgs, score=0.160, total=   0.0s\n",
      "[CV] C=0.001, penalty=l2, solver=lbfgs ...............................\n",
      "[CV] ... C=0.001, penalty=l2, solver=lbfgs, score=0.127, total=   0.0s\n",
      "[CV] C=0.001, penalty=l2, solver=lbfgs ...............................\n",
      "[CV] ... C=0.001, penalty=l2, solver=lbfgs, score=0.100, total=   0.0s\n",
      "[CV] C=0.001, penalty=l2, solver=liblinear ...........................\n",
      "[CV]  C=0.001, penalty=l2, solver=liblinear, score=0.253, total=   0.0s\n",
      "[CV] C=0.001, penalty=l2, solver=liblinear ...........................\n",
      "[CV]  C=0.001, penalty=l2, solver=liblinear, score=0.260, total=   0.0s\n",
      "[CV] C=0.001, penalty=l2, solver=liblinear ...........................\n",
      "[CV]  C=0.001, penalty=l2, solver=liblinear, score=0.293, total=   0.0s\n",
      "[CV] C=0.001, penalty=l2, solver=liblinear ...........................\n",
      "[CV]  C=0.001, penalty=l2, solver=liblinear, score=0.360, total=   0.0s\n",
      "[CV] C=0.001, penalty=l2, solver=liblinear ...........................\n",
      "[CV]  C=0.001, penalty=l2, solver=liblinear, score=0.327, total=   0.0s\n",
      "[CV] C=0.0001, penalty=l1, solver=newton-cg ..........................\n",
      "[CV]  C=0.0001, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=0.0001, penalty=l1, solver=newton-cg ..........................\n",
      "[CV]  C=0.0001, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=0.0001, penalty=l1, solver=newton-cg ..........................\n",
      "[CV]  C=0.0001, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=0.0001, penalty=l1, solver=newton-cg ..........................\n",
      "[CV]  C=0.0001, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=0.0001, penalty=l1, solver=newton-cg ..........................\n",
      "[CV]  C=0.0001, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=0.0001, penalty=l1, solver=lbfgs ..............................\n",
      "[CV] .... C=0.0001, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=0.0001, penalty=l1, solver=lbfgs ..............................\n",
      "[CV] .... C=0.0001, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=0.0001, penalty=l1, solver=lbfgs ..............................\n",
      "[CV] .... C=0.0001, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=0.0001, penalty=l1, solver=lbfgs ..............................\n",
      "[CV] .... C=0.0001, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=0.0001, penalty=l1, solver=lbfgs ..............................\n",
      "[CV] .... C=0.0001, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=0.0001, penalty=l1, solver=liblinear ..........................\n",
      "[CV]  C=0.0001, penalty=l1, solver=liblinear, score=0.087, total=   0.0s\n",
      "[CV] C=0.0001, penalty=l1, solver=liblinear ..........................\n",
      "[CV]  C=0.0001, penalty=l1, solver=liblinear, score=0.093, total=   0.0s\n",
      "[CV] C=0.0001, penalty=l1, solver=liblinear ..........................\n",
      "[CV]  C=0.0001, penalty=l1, solver=liblinear, score=0.093, total=   0.0s\n",
      "[CV] C=0.0001, penalty=l1, solver=liblinear ..........................\n",
      "[CV]  C=0.0001, penalty=l1, solver=liblinear, score=0.093, total=   0.0s\n",
      "[CV] C=0.0001, penalty=l1, solver=liblinear ..........................\n",
      "[CV]  C=0.0001, penalty=l1, solver=liblinear, score=0.093, total=   0.0s\n",
      "[CV] C=0.0001, penalty=l2, solver=newton-cg ..........................\n",
      "[CV]  C=0.0001, penalty=l2, solver=newton-cg, score=0.107, total=   0.0s\n",
      "[CV] C=0.0001, penalty=l2, solver=newton-cg ..........................\n",
      "[CV]  C=0.0001, penalty=l2, solver=newton-cg, score=0.107, total=   0.0s\n",
      "[CV] C=0.0001, penalty=l2, solver=newton-cg ..........................\n",
      "[CV]  C=0.0001, penalty=l2, solver=newton-cg, score=0.107, total=   0.0s\n",
      "[CV] C=0.0001, penalty=l2, solver=newton-cg ..........................\n",
      "[CV]  C=0.0001, penalty=l2, solver=newton-cg, score=0.107, total=   0.0s\n",
      "[CV] C=0.0001, penalty=l2, solver=newton-cg ..........................\n",
      "[CV]  C=0.0001, penalty=l2, solver=newton-cg, score=0.100, total=   0.0s\n",
      "[CV] C=0.0001, penalty=l2, solver=lbfgs ..............................\n",
      "[CV] .. C=0.0001, penalty=l2, solver=lbfgs, score=0.107, total=   0.0s\n",
      "[CV] C=0.0001, penalty=l2, solver=lbfgs ..............................\n",
      "[CV] .. C=0.0001, penalty=l2, solver=lbfgs, score=0.107, total=   0.0s\n",
      "[CV] C=0.0001, penalty=l2, solver=lbfgs ..............................\n",
      "[CV] .. C=0.0001, penalty=l2, solver=lbfgs, score=0.107, total=   0.0s\n",
      "[CV] C=0.0001, penalty=l2, solver=lbfgs ..............................\n",
      "[CV] .. C=0.0001, penalty=l2, solver=lbfgs, score=0.107, total=   0.0s\n",
      "[CV] C=0.0001, penalty=l2, solver=lbfgs ..............................\n",
      "[CV] .. C=0.0001, penalty=l2, solver=lbfgs, score=0.100, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bvera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\bvera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\bvera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\bvera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=0.0001, penalty=l2, solver=liblinear ..........................\n",
      "[CV]  C=0.0001, penalty=l2, solver=liblinear, score=0.207, total=   0.0s\n",
      "[CV] C=0.0001, penalty=l2, solver=liblinear ..........................\n",
      "[CV]  C=0.0001, penalty=l2, solver=liblinear, score=0.200, total=   0.0s\n",
      "[CV] C=0.0001, penalty=l2, solver=liblinear ..........................\n",
      "[CV]  C=0.0001, penalty=l2, solver=liblinear, score=0.240, total=   0.0s\n",
      "[CV] C=0.0001, penalty=l2, solver=liblinear ..........................\n",
      "[CV]  C=0.0001, penalty=l2, solver=liblinear, score=0.293, total=   0.0s\n",
      "[CV] C=0.0001, penalty=l2, solver=liblinear ..........................\n",
      "[CV]  C=0.0001, penalty=l2, solver=liblinear, score=0.287, total=   0.0s\n",
      "[CV] C=0.0005, penalty=l1, solver=newton-cg ..........................\n",
      "[CV]  C=0.0005, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=0.0005, penalty=l1, solver=newton-cg ..........................\n",
      "[CV]  C=0.0005, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=0.0005, penalty=l1, solver=newton-cg ..........................\n",
      "[CV]  C=0.0005, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=0.0005, penalty=l1, solver=newton-cg ..........................\n",
      "[CV]  C=0.0005, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=0.0005, penalty=l1, solver=newton-cg ..........................\n",
      "[CV]  C=0.0005, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=0.0005, penalty=l1, solver=lbfgs ..............................\n",
      "[CV] .... C=0.0005, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=0.0005, penalty=l1, solver=lbfgs ..............................\n",
      "[CV] .... C=0.0005, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=0.0005, penalty=l1, solver=lbfgs ..............................\n",
      "[CV] .... C=0.0005, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=0.0005, penalty=l1, solver=lbfgs ..............................\n",
      "[CV] .... C=0.0005, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=0.0005, penalty=l1, solver=lbfgs ..............................\n",
      "[CV] .... C=0.0005, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=0.0005, penalty=l1, solver=liblinear ..........................\n",
      "[CV]  C=0.0005, penalty=l1, solver=liblinear, score=0.087, total=   0.0s\n",
      "[CV] C=0.0005, penalty=l1, solver=liblinear ..........................\n",
      "[CV]  C=0.0005, penalty=l1, solver=liblinear, score=0.093, total=   0.0s\n",
      "[CV] C=0.0005, penalty=l1, solver=liblinear ..........................\n",
      "[CV]  C=0.0005, penalty=l1, solver=liblinear, score=0.093, total=   0.0s\n",
      "[CV] C=0.0005, penalty=l1, solver=liblinear ..........................\n",
      "[CV]  C=0.0005, penalty=l1, solver=liblinear, score=0.093, total=   0.0s\n",
      "[CV] C=0.0005, penalty=l1, solver=liblinear ..........................\n",
      "[CV]  C=0.0005, penalty=l1, solver=liblinear, score=0.093, total=   0.0s\n",
      "[CV] C=0.0005, penalty=l2, solver=newton-cg ..........................\n",
      "[CV]  C=0.0005, penalty=l2, solver=newton-cg, score=0.107, total=   0.0s\n",
      "[CV] C=0.0005, penalty=l2, solver=newton-cg ..........................\n",
      "[CV]  C=0.0005, penalty=l2, solver=newton-cg, score=0.107, total=   0.0s\n",
      "[CV] C=0.0005, penalty=l2, solver=newton-cg ..........................\n",
      "[CV]  C=0.0005, penalty=l2, solver=newton-cg, score=0.107, total=   0.0s\n",
      "[CV] C=0.0005, penalty=l2, solver=newton-cg ..........................\n",
      "[CV]  C=0.0005, penalty=l2, solver=newton-cg, score=0.107, total=   0.0s\n",
      "[CV] C=0.0005, penalty=l2, solver=newton-cg ..........................\n",
      "[CV]  C=0.0005, penalty=l2, solver=newton-cg, score=0.100, total=   0.0s\n",
      "[CV] C=0.0005, penalty=l2, solver=lbfgs ..............................\n",
      "[CV] .. C=0.0005, penalty=l2, solver=lbfgs, score=0.107, total=   0.0s\n",
      "[CV] C=0.0005, penalty=l2, solver=lbfgs ..............................\n",
      "[CV] .. C=0.0005, penalty=l2, solver=lbfgs, score=0.107, total=   0.0s\n",
      "[CV] C=0.0005, penalty=l2, solver=lbfgs ..............................\n",
      "[CV] .. C=0.0005, penalty=l2, solver=lbfgs, score=0.107, total=   0.0s\n",
      "[CV] C=0.0005, penalty=l2, solver=lbfgs ..............................\n",
      "[CV] .. C=0.0005, penalty=l2, solver=lbfgs, score=0.107, total=   0.0s\n",
      "[CV] C=0.0005, penalty=l2, solver=lbfgs ..............................\n",
      "[CV] .. C=0.0005, penalty=l2, solver=lbfgs, score=0.100, total=   0.0s\n",
      "[CV] C=0.0005, penalty=l2, solver=liblinear ..........................\n",
      "[CV]  C=0.0005, penalty=l2, solver=liblinear, score=0.253, total=   0.0s\n",
      "[CV] C=0.0005, penalty=l2, solver=liblinear ..........................\n",
      "[CV]  C=0.0005, penalty=l2, solver=liblinear, score=0.233, total=   0.0s\n",
      "[CV] C=0.0005, penalty=l2, solver=liblinear ..........................\n",
      "[CV]  C=0.0005, penalty=l2, solver=liblinear, score=0.253, total=   0.0s\n",
      "[CV] C=0.0005, penalty=l2, solver=liblinear ..........................\n",
      "[CV]  C=0.0005, penalty=l2, solver=liblinear, score=0.320, total=   0.0s\n",
      "[CV] C=0.0005, penalty=l2, solver=liblinear ..........................\n",
      "[CV]  C=0.0005, penalty=l2, solver=liblinear, score=0.300, total=   0.0s\n",
      "[CV] C=0.005, penalty=l1, solver=newton-cg ...........................\n",
      "[CV] . C=0.005, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=0.005, penalty=l1, solver=newton-cg ...........................\n",
      "[CV] . C=0.005, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=0.005, penalty=l1, solver=newton-cg ...........................\n",
      "[CV] . C=0.005, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=0.005, penalty=l1, solver=newton-cg ...........................\n",
      "[CV] . C=0.005, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=0.005, penalty=l1, solver=newton-cg ...........................\n",
      "[CV] . C=0.005, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=0.005, penalty=l1, solver=lbfgs ...............................\n",
      "[CV] ..... C=0.005, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=0.005, penalty=l1, solver=lbfgs ...............................\n",
      "[CV] ..... C=0.005, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=0.005, penalty=l1, solver=lbfgs ...............................\n",
      "[CV] ..... C=0.005, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=0.005, penalty=l1, solver=lbfgs ...............................\n",
      "[CV] ..... C=0.005, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=0.005, penalty=l1, solver=lbfgs ...............................\n",
      "[CV] ..... C=0.005, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=0.005, penalty=l1, solver=liblinear ...........................\n",
      "[CV]  C=0.005, penalty=l1, solver=liblinear, score=0.107, total=   0.0s\n",
      "[CV] C=0.005, penalty=l1, solver=liblinear ...........................\n",
      "[CV]  C=0.005, penalty=l1, solver=liblinear, score=0.107, total=   0.0s\n",
      "[CV] C=0.005, penalty=l1, solver=liblinear ...........................\n",
      "[CV]  C=0.005, penalty=l1, solver=liblinear, score=0.107, total=   0.0s\n",
      "[CV] C=0.005, penalty=l1, solver=liblinear ...........................\n",
      "[CV]  C=0.005, penalty=l1, solver=liblinear, score=0.107, total=   0.0s\n",
      "[CV] C=0.005, penalty=l1, solver=liblinear ...........................\n",
      "[CV]  C=0.005, penalty=l1, solver=liblinear, score=0.100, total=   0.0s\n",
      "[CV] C=0.005, penalty=l2, solver=newton-cg ...........................\n",
      "[CV]  C=0.005, penalty=l2, solver=newton-cg, score=0.307, total=   0.0s\n",
      "[CV] C=0.005, penalty=l2, solver=newton-cg ...........................\n",
      "[CV]  C=0.005, penalty=l2, solver=newton-cg, score=0.307, total=   0.0s\n",
      "[CV] C=0.005, penalty=l2, solver=newton-cg ...........................\n",
      "[CV]  C=0.005, penalty=l2, solver=newton-cg, score=0.333, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bvera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\bvera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "[Parallel(n_jobs=1)]: Done 270 out of 270 | elapsed:    4.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=0.005, penalty=l2, solver=newton-cg ...........................\n",
      "[CV]  C=0.005, penalty=l2, solver=newton-cg, score=0.333, total=   0.0s\n",
      "[CV] C=0.005, penalty=l2, solver=newton-cg ...........................\n",
      "[CV]  C=0.005, penalty=l2, solver=newton-cg, score=0.247, total=   0.0s\n",
      "[CV] C=0.005, penalty=l2, solver=lbfgs ...............................\n",
      "[CV] ... C=0.005, penalty=l2, solver=lbfgs, score=0.307, total=   0.0s\n",
      "[CV] C=0.005, penalty=l2, solver=lbfgs ...............................\n",
      "[CV] ... C=0.005, penalty=l2, solver=lbfgs, score=0.307, total=   0.0s\n",
      "[CV] C=0.005, penalty=l2, solver=lbfgs ...............................\n",
      "[CV] ... C=0.005, penalty=l2, solver=lbfgs, score=0.333, total=   0.0s\n",
      "[CV] C=0.005, penalty=l2, solver=lbfgs ...............................\n",
      "[CV] ... C=0.005, penalty=l2, solver=lbfgs, score=0.333, total=   0.0s\n",
      "[CV] C=0.005, penalty=l2, solver=lbfgs ...............................\n",
      "[CV] ... C=0.005, penalty=l2, solver=lbfgs, score=0.253, total=   0.0s\n",
      "[CV] C=0.005, penalty=l2, solver=liblinear ...........................\n",
      "[CV]  C=0.005, penalty=l2, solver=liblinear, score=0.307, total=   0.0s\n",
      "[CV] C=0.005, penalty=l2, solver=liblinear ...........................\n",
      "[CV]  C=0.005, penalty=l2, solver=liblinear, score=0.353, total=   0.0s\n",
      "[CV] C=0.005, penalty=l2, solver=liblinear ...........................\n",
      "[CV]  C=0.005, penalty=l2, solver=liblinear, score=0.333, total=   0.0s\n",
      "[CV] C=0.005, penalty=l2, solver=liblinear ...........................\n",
      "[CV]  C=0.005, penalty=l2, solver=liblinear, score=0.400, total=   0.0s\n",
      "[CV] C=0.005, penalty=l2, solver=liblinear ...........................\n",
      "[CV]  C=0.005, penalty=l2, solver=liblinear, score=0.340, total=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=LogisticRegression(C=10, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='auto',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='newton-cg',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': [100, 10, 1.0, 0.1, 0.01, 0.001, 0.0001, 0.0005,\n",
       "                               0.005],\n",
       "                         'penalty': ['l1', 'l2'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.5186666666666667\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.348"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train_scaled, y_train)\n",
    "clf.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=200, max_depth= 10, min_samples_leaf= 1, min_samples_split= 5)\n",
    "rf = rf.fit(X_train_scaled, y_train)\n",
    "rf.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = cleaned_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.12592038637041508, 'danceability'),\n",
       " (0.12544906761006375, 'acousticness'),\n",
       " (0.11079362983903518, 'valence'),\n",
       " (0.10916664339489268, 'energy'),\n",
       " (0.10801120178850453, 'speechiness'),\n",
       " (0.1059209011492661, 'instrumentalness'),\n",
       " (0.09920971711539427, 'loudness'),\n",
       " (0.06177975716402704, 'duration_ms'),\n",
       " (0.05663326139866322, 'tempo'),\n",
       " (0.053543594524613804, 'liveness'),\n",
       " (0.03030668724099855, 'key'),\n",
       " (0.013265152404125732, 'mode')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(rf.feature_importances_, feature_names), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.9986666666666667\n",
      "Testing Data Score: 0.348\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {clf.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {clf.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistical Testing Data Score: 0.472\n",
      "Decision Tree Testing Data Score: 0.348\n",
      "Random Forest Testing Data Score: 0.48\n"
     ]
    }
   ],
   "source": [
    "print(f\"Logistical Testing Data Score: {classifier.score(X_test_scaled, y_test)}\")\n",
    "print(f\"Decision Tree Testing Data Score: {clf.score(X_test_scaled, y_test)}\")\n",
    "print(f\"Random Forest Testing Data Score: {rf.score(X_test_scaled, y_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 600, num = 3)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 20, num = 2)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators': n_estimators,\n",
    "               \n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               }\n",
    "grid = GridSearchCV(rf, param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "[CV] max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200, score=0.540, total=   0.3s\n",
      "[CV] max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200, score=0.553, total=   0.3s\n",
      "[CV] max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200, score=0.540, total=   0.3s\n",
      "[CV] max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200, score=0.493, total=   0.3s\n",
      "[CV] max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200, score=0.520, total=   0.3s\n",
      "[CV] max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=400, score=0.540, total=   0.6s\n",
      "[CV] max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=400, score=0.547, total=   0.6s\n",
      "[CV] max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=400, score=0.553, total=   0.6s\n",
      "[CV] max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=400, score=0.480, total=   0.6s\n",
      "[CV] max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=400, score=0.520, total=   0.6s\n",
      "[CV] max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=600 \n",
      "[CV]  max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=600, score=0.553, total=   0.9s\n",
      "[CV] max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=600 \n",
      "[CV]  max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=600, score=0.580, total=   0.9s\n",
      "[CV] max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=600 \n",
      "[CV]  max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=600, score=0.553, total=   0.9s\n",
      "[CV] max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=600 \n",
      "[CV]  max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=600, score=0.500, total=   0.9s\n",
      "[CV] max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=600 \n",
      "[CV]  max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=600, score=0.520, total=   0.9s\n",
      "[CV] max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200, score=0.527, total=   0.3s\n",
      "[CV] max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200, score=0.560, total=   0.3s\n",
      "[CV] max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200, score=0.547, total=   0.3s\n",
      "[CV] max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200, score=0.507, total=   0.3s\n",
      "[CV] max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200, score=0.520, total=   0.3s\n",
      "[CV] max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=400, score=0.533, total=   0.6s\n",
      "[CV] max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=400, score=0.547, total=   0.6s\n",
      "[CV] max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=400, score=0.540, total=   0.6s\n",
      "[CV] max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=400, score=0.507, total=   0.6s\n",
      "[CV] max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=400, score=0.527, total=   0.6s\n",
      "[CV] max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=600 \n",
      "[CV]  max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=600, score=0.540, total=   0.9s\n",
      "[CV] max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=600 \n",
      "[CV]  max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=600, score=0.560, total=   0.9s\n",
      "[CV] max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=600 \n",
      "[CV]  max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=600, score=0.573, total=   0.9s\n",
      "[CV] max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=600 \n",
      "[CV]  max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=600, score=0.500, total=   0.9s\n",
      "[CV] max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=600 \n",
      "[CV]  max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=600, score=0.520, total=   0.9s\n",
      "[CV] max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200, score=0.527, total=   0.3s\n",
      "[CV] max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200, score=0.540, total=   0.3s\n",
      "[CV] max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200, score=0.553, total=   0.3s\n",
      "[CV] max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200, score=0.493, total=   0.3s\n",
      "[CV] max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200, score=0.520, total=   0.3s\n",
      "[CV] max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=400, score=0.547, total=   0.6s\n",
      "[CV] max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=400, score=0.547, total=   0.6s\n",
      "[CV] max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=400, score=0.573, total=   0.6s\n",
      "[CV] max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=400, score=0.500, total=   0.6s\n",
      "[CV] max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=400, score=0.513, total=   0.6s\n",
      "[CV] max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=600 \n",
      "[CV]  max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=600, score=0.540, total=   0.9s\n",
      "[CV] max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=600 \n",
      "[CV]  max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=600, score=0.560, total=   0.9s\n",
      "[CV] max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=600 \n",
      "[CV]  max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=600, score=0.553, total=   0.9s\n",
      "[CV] max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=600 \n",
      "[CV]  max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=600, score=0.500, total=   0.9s\n",
      "[CV] max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=600 \n",
      "[CV]  max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=600, score=0.520, total=   0.9s\n",
      "[CV] max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200, score=0.547, total=   0.3s\n",
      "[CV] max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200, score=0.560, total=   0.3s\n",
      "[CV] max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200, score=0.553, total=   0.3s\n",
      "[CV] max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200, score=0.520, total=   0.3s\n",
      "[CV] max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200, score=0.533, total=   0.3s\n",
      "[CV] max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=400, score=0.540, total=   0.6s\n",
      "[CV] max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=400, score=0.547, total=   0.6s\n",
      "[CV] max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=400, score=0.560, total=   0.6s\n",
      "[CV] max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=400, score=0.507, total=   0.6s\n",
      "[CV] max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=400, score=0.527, total=   0.6s\n",
      "[CV] max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=600 \n",
      "[CV]  max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=600, score=0.547, total=   0.9s\n",
      "[CV] max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=600 \n",
      "[CV]  max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=600, score=0.547, total=   0.9s\n",
      "[CV] max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=600 \n",
      "[CV]  max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=600, score=0.587, total=   0.9s\n",
      "[CV] max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=600 \n",
      "[CV]  max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=600, score=0.487, total=   0.9s\n",
      "[CV] max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=600 \n",
      "[CV]  max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=600, score=0.513, total=   0.9s\n",
      "[CV] max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200, score=0.553, total=   0.3s\n",
      "[CV] max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200, score=0.560, total=   0.3s\n",
      "[CV] max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200, score=0.567, total=   0.3s\n",
      "[CV] max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200, score=0.500, total=   0.3s\n",
      "[CV] max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200, score=0.547, total=   0.3s\n",
      "[CV] max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=400, score=0.573, total=   0.6s\n",
      "[CV] max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=400, score=0.547, total=   0.6s\n",
      "[CV] max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=400, score=0.513, total=   0.6s\n",
      "[CV] max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=400, score=0.507, total=   0.6s\n",
      "[CV] max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=400, score=0.513, total=   0.6s\n",
      "[CV] max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=600 \n",
      "[CV]  max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=600, score=0.547, total=   0.9s\n",
      "[CV] max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=600 \n",
      "[CV]  max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=600, score=0.567, total=   0.9s\n",
      "[CV] max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=600 \n",
      "[CV]  max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=600, score=0.560, total=   0.9s\n",
      "[CV] max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=600 \n",
      "[CV]  max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=600, score=0.493, total=   0.9s\n",
      "[CV] max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=600 \n",
      "[CV]  max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=600, score=0.520, total=   0.9s\n",
      "[CV] max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200, score=0.553, total=   0.3s\n",
      "[CV] max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200, score=0.547, total=   0.3s\n",
      "[CV] max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200, score=0.547, total=   0.3s\n",
      "[CV] max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200, score=0.500, total=   0.3s\n",
      "[CV] max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200, score=0.527, total=   0.3s\n",
      "[CV] max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=400, score=0.573, total=   0.6s\n",
      "[CV] max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=400, score=0.540, total=   0.6s\n",
      "[CV] max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=400, score=0.553, total=   0.6s\n",
      "[CV] max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=400, score=0.507, total=   0.6s\n",
      "[CV] max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=400, score=0.533, total=   0.6s\n",
      "[CV] max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=600 \n",
      "[CV]  max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=600, score=0.547, total=   0.9s\n",
      "[CV] max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=600 \n",
      "[CV]  max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=600, score=0.547, total=   0.9s\n",
      "[CV] max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=600 \n",
      "[CV]  max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=600, score=0.553, total=   0.9s\n",
      "[CV] max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=600 \n",
      "[CV]  max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=600, score=0.500, total=   0.9s\n",
      "[CV] max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=600 \n",
      "[CV]  max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=600, score=0.520, total=   0.9s\n",
      "[CV] max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200, score=0.507, total=   0.3s\n",
      "[CV] max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200, score=0.567, total=   0.3s\n",
      "[CV] max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200, score=0.533, total=   0.3s\n",
      "[CV] max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200, score=0.487, total=   0.3s\n",
      "[CV] max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200, score=0.533, total=   0.3s\n",
      "[CV] max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=400, score=0.540, total=   0.6s\n",
      "[CV] max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=400, score=0.560, total=   0.6s\n",
      "[CV] max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=400, score=0.567, total=   0.6s\n",
      "[CV] max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=400, score=0.500, total=   0.6s\n",
      "[CV] max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=400, score=0.520, total=   0.6s\n",
      "[CV] max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=600 \n",
      "[CV]  max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=600, score=0.547, total=   0.9s\n",
      "[CV] max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=600 \n",
      "[CV]  max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=600, score=0.547, total=   0.9s\n",
      "[CV] max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=600 \n",
      "[CV]  max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=600, score=0.560, total=   0.9s\n",
      "[CV] max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=600 \n",
      "[CV]  max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=600, score=0.500, total=   0.9s\n",
      "[CV] max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=600 \n",
      "[CV]  max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=600, score=0.527, total=   0.9s\n",
      "[CV] max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200, score=0.547, total=   0.3s\n",
      "[CV] max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200, score=0.540, total=   0.3s\n",
      "[CV] max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200, score=0.547, total=   0.3s\n",
      "[CV] max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200, score=0.507, total=   0.3s\n",
      "[CV] max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200, score=0.520, total=   0.3s\n",
      "[CV] max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=400, score=0.520, total=   0.6s\n",
      "[CV] max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=400, score=0.540, total=   0.6s\n",
      "[CV] max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=400, score=0.553, total=   0.6s\n",
      "[CV] max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=400, score=0.507, total=   0.6s\n",
      "[CV] max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=400, score=0.527, total=   0.6s\n",
      "[CV] max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=600 \n",
      "[CV]  max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=600, score=0.540, total=   0.9s\n",
      "[CV] max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=600 \n",
      "[CV]  max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=600, score=0.553, total=   0.9s\n",
      "[CV] max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=600 \n",
      "[CV]  max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=600, score=0.560, total=   0.9s\n",
      "[CV] max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=600 \n",
      "[CV]  max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=600, score=0.500, total=   0.9s\n",
      "[CV] max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=600 \n",
      "[CV]  max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=600, score=0.527, total=   0.9s\n",
      "[CV] max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200, score=0.547, total=   0.3s\n",
      "[CV] max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200, score=0.547, total=   0.3s\n",
      "[CV] max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200, score=0.547, total=   0.3s\n",
      "[CV] max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200, score=0.507, total=   0.3s\n",
      "[CV] max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200, score=0.533, total=   0.3s\n",
      "[CV] max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=400, score=0.540, total=   0.6s\n",
      "[CV] max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=400, score=0.580, total=   0.6s\n",
      "[CV] max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=400, score=0.533, total=   0.6s\n",
      "[CV] max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=400, score=0.493, total=   0.6s\n",
      "[CV] max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=400, score=0.527, total=   0.6s\n",
      "[CV] max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=600 \n",
      "[CV]  max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=600, score=0.533, total=   0.9s\n",
      "[CV] max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=600 \n",
      "[CV]  max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=600, score=0.560, total=   0.9s\n",
      "[CV] max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=600 \n",
      "[CV]  max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=600, score=0.573, total=   0.9s\n",
      "[CV] max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=600 \n",
      "[CV]  max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=600, score=0.500, total=   0.9s\n",
      "[CV] max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=600 \n",
      "[CV]  max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=600, score=0.520, total=   0.9s\n",
      "[CV] max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200, score=0.547, total=   0.3s\n",
      "[CV] max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200, score=0.553, total=   0.3s\n",
      "[CV] max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200, score=0.553, total=   0.3s\n",
      "[CV] max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200, score=0.527, total=   0.3s\n",
      "[CV] max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200, score=0.507, total=   0.3s\n",
      "[CV] max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=400, score=0.527, total=   0.6s\n",
      "[CV] max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=400, score=0.553, total=   0.6s\n",
      "[CV] max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=400, score=0.567, total=   0.6s\n",
      "[CV] max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=400, score=0.513, total=   0.6s\n",
      "[CV] max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=400, score=0.533, total=   0.6s\n",
      "[CV] max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=600 \n",
      "[CV]  max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=600, score=0.547, total=   0.9s\n",
      "[CV] max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=600 \n",
      "[CV]  max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=600, score=0.527, total=   0.9s\n",
      "[CV] max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=600 \n",
      "[CV]  max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=600, score=0.547, total=   0.9s\n",
      "[CV] max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=600 \n",
      "[CV]  max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=600, score=0.500, total=   0.9s\n",
      "[CV] max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=600 \n",
      "[CV]  max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=600, score=0.533, total=   0.9s\n",
      "[CV] max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200, score=0.547, total=   0.3s\n",
      "[CV] max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200, score=0.527, total=   0.3s\n",
      "[CV] max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200, score=0.560, total=   0.3s\n",
      "[CV] max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200, score=0.520, total=   0.3s\n",
      "[CV] max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200 \n",
      "[CV]  max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200, score=0.513, total=   0.3s\n",
      "[CV] max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=400, score=0.553, total=   0.6s\n",
      "[CV] max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=400, score=0.553, total=   0.6s\n",
      "[CV] max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=400, score=0.540, total=   0.6s\n",
      "[CV] max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=400, score=0.493, total=   0.6s\n",
      "[CV] max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=400 \n",
      "[CV]  max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=400, score=0.513, total=   0.6s\n",
      "[CV] max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=600 \n",
      "[CV]  max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=600, score=0.540, total=   0.9s\n",
      "[CV] max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=600 \n",
      "[CV]  max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=600, score=0.560, total=   0.9s\n",
      "[CV] max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=600 \n",
      "[CV]  max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=600, score=0.580, total=   0.9s\n",
      "[CV] max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=600 \n",
      "[CV]  max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=600, score=0.500, total=   0.9s\n",
      "[CV] max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=600 \n",
      "[CV]  max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=600, score=0.527, total=   0.9s\n",
      "[CV] max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200, score=0.567, total=   0.3s\n",
      "[CV] max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200, score=0.560, total=   0.3s\n",
      "[CV] max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200, score=0.573, total=   0.3s\n",
      "[CV] max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200, score=0.513, total=   0.3s\n",
      "[CV] max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200 \n",
      "[CV]  max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200, score=0.520, total=   0.3s\n",
      "[CV] max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=400, score=0.527, total=   0.6s\n",
      "[CV] max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=400, score=0.553, total=   0.6s\n",
      "[CV] max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=400, score=0.567, total=   0.6s\n",
      "[CV] max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=400, score=0.500, total=   0.6s\n",
      "[CV] max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=400 \n",
      "[CV]  max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=400, score=0.520, total=   0.6s\n",
      "[CV] max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=600 \n",
      "[CV]  max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=600, score=0.540, total=   0.9s\n",
      "[CV] max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=600 \n",
      "[CV]  max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=600, score=0.540, total=   0.9s\n",
      "[CV] max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=600 \n",
      "[CV]  max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=600, score=0.533, total=   0.9s\n",
      "[CV] max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=600 \n",
      "[CV]  max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=600, score=0.500, total=   0.9s\n",
      "[CV] max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=600 \n",
      "[CV]  max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=600, score=0.520, total=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 180 out of 180 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=10,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=5,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=200, n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'max_depth': [10, 20, None],\n",
       "                         'min_samples_leaf': [1, 2],\n",
       "                         'min_samples_split': [2, 5],\n",
       "                         'n_estimators': [200, 400, 600]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
